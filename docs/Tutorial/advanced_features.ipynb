{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Features\n",
    "\n",
    "When analyzing the real world datasets, we may have the following targets:\n",
    "\n",
    "1. certain variables must be selected when some prior information is given;\n",
    "2. selecting the weak signal variables when the prediction performance is mainly interested;\n",
    "3. identifying predictors when group structure are provided;\n",
    "4. pre-excluding a part of predictors when datasets have ultra high-dimensional predictors;\n",
    "5. specify the division of sample in cross validation;\n",
    "6. specify the initial active set before splicing.\n",
    "\n",
    "In the following content, we will illustrate the statistic methods to reach these targets in a one-by-one manner, and give quick examples to show how to perform the statistic methods in `abessLm` and the same steps can be implemented in all methods. Actually, in our methods, the targets can be properly handled by simply change some default arguments in the functions. \n",
    "\n",
    "## Nuisance Regression\n",
    "\n",
    "Nuisance regression refers to best subset selection with some prior information that some variables are required to stay in the active set. For example, if we are interested in a certain gene and want to find out what other genes are associated with the response when this particular gene shows effect.\n",
    "\n",
    "In the `abessLm()` (or other methods), the argument `always_select` is designed to realize this goal. User can pass a vector containing the indexes of the target variables to `always_select`. Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real coefficients:\n",
      " [  0.           0.         115.01218243   0.           0.\n",
      "  81.84924757   0.           0.           0.           0.\n",
      " 104.77568224  64.30426355   0.           0.           0.\n",
      "   0.           0.           0.         108.5408557    0.        ] \n",
      "\n",
      "real coefficients' indexes:\n",
      " [ 2  5 10 11 18]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from abess.datasets import make_glm_data\n",
    "from abess.linear import abessLm\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# gene data\n",
    "n = 100\n",
    "p = 20\n",
    "k = 5\n",
    "dt = make_glm_data(n = n, p = p, k = k, family = 'gaussian')\n",
    "print('real coefficients:\\n', dt.coef_, '\\n')\n",
    "print('real coefficients\\' indexes:\\n', np.nonzero(dt.coef_)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted coefficients:\n",
      " [  0.           0.         114.93792167   0.           0.\n",
      "  81.8124385    0.           0.           0.           0.\n",
      " 104.67076232  64.40856101   0.           0.           0.\n",
      "   0.           0.           0.         108.73726174   0.        ] \n",
      "\n",
      "fitted coefficients' indexes:\n",
      " [ 2  5 10 11 18]\n"
     ]
    }
   ],
   "source": [
    "model = abessLm(support_size = range(0, 6))\n",
    "model.fit(dt.x, dt.y)\n",
    "print('fitted coefficients:\\n', model.coef_, '\\n')\n",
    "print('fitted coefficients\\' indexes:\\n', np.nonzero(model.coef_)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The coefficients are located in \\[2, 5, 10, 11, 18\\]. \n",
    "But if we suppose that the 7th and 8th variables are worthy to be included in the model, we can call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted coefficients:\n",
      " [  0.           0.         117.18370615   0.           0.\n",
      "   0.           0.           5.09643891  -1.00521149   0.\n",
      "  91.65760504   0.           0.           0.           0.\n",
      "   0.           0.           0.         121.21120638   0.        ] \n",
      "\n",
      "fitted coefficients' indexes:\n",
      " [ 2  7  8 10 18]\n"
     ]
    }
   ],
   "source": [
    "model = abessLm(support_size = range(0, 6), always_select = [7, 8])\n",
    "model.fit(dt.x, dt.y)\n",
    "print('fitted coefficients:\\n', model.coef_, '\\n')\n",
    "print('fitted coefficients\\' indexes:\\n', np.nonzero(model.coef_)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the variables we chosen are always in the model.\n",
    "\n",
    "## Regularized Adaptive Best Subset Selection\n",
    "\n",
    "In some cases, especially under low signal-to-noise ratio (SNR) setting or predictors are highly correlated, the vallina type of $L_0$ constrained model may not be satisfying and a more sophisticated trade-off between bias and variance is needed. Under this concern, the `abess` pakcage provides option of best subset selection with $L_2$ norm regularization called the regularized bess. The model has this following form:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\arg\\min_\\beta L(\\beta) + \\alpha \\|\\beta\\|_2^2.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "To implement the regularized bess, user need to specify a value to an additive argument `alpha` in the `abessLm()` function (or other methods). This value corresponds to the penalization parameter in the model above. \n",
    "\n",
    "Letâ€™s test the regularized best subset selection against the no-regularized one over 100 replicas in terms of prediction performance. With argument `snr` in `make_glm_data()`, we can add white noise into generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal model's loss: 24.709066304317844\n",
      "regularized model's loss: 23.416157533057604\n"
     ]
    }
   ],
   "source": [
    "loss = np.zeros((2, 100))\n",
    "coef = np.repeat([1, 0], [5, 25])\n",
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    train = make_glm_data(n = 100, p = 30, k = 5, family = 'gaussian', coef_ = coef, snr = 0.05)\n",
    "    np.random.seed(i + 100)\n",
    "    test = make_glm_data(n = 100, p = 30, k = 5, family = 'gaussian', coef_ = coef, snr = 0.05)\n",
    "    \n",
    "    # normal\n",
    "    model = abessLm()\n",
    "    model.fit(train.x, train.y)\n",
    "    loss[0, i] = np.linalg.norm(model.predict(test.x) - test.y)\n",
    "    # regularized\n",
    "    model = abessLm(alpha = 0.7)\n",
    "    model.fit(train.x, train.y)\n",
    "    loss[1, i] = np.linalg.norm(model.predict(test.x) - test.y)\n",
    "\n",
    "print(\"normal model's loss:\", np.mean(loss[0,:]))\n",
    "print(\"regularized model's loss:\", np.mean(loss[1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularized model has a lower test loss. And we can also make a boxplot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-07-20T11:15:13.884008</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 378.465625 248.518125 \nL 378.465625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m4511704269\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"120.165625\" xlink:href=\"#m4511704269\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- ABESS -->\n      <g transform=\"translate(103.807031 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2188 4044 \nL 1331 1722 \nL 3047 1722 \nL 2188 4044 \nz\nM 1831 4666 \nL 2547 4666 \nL 4325 0 \nL 3669 0 \nL 3244 1197 \nL 1141 1197 \nL 716 0 \nL 50 0 \nL 1831 4666 \nz\n\" id=\"DejaVuSans-41\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 1259 2228 \nL 1259 519 \nL 2272 519 \nQ 2781 519 3026 730 \nQ 3272 941 3272 1375 \nQ 3272 1813 3026 2020 \nQ 2781 2228 2272 2228 \nL 1259 2228 \nz\nM 1259 4147 \nL 1259 2741 \nL 2194 2741 \nQ 2656 2741 2882 2914 \nQ 3109 3088 3109 3444 \nQ 3109 3797 2882 3972 \nQ 2656 4147 2194 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2241 4666 \nQ 2963 4666 3353 4366 \nQ 3744 4066 3744 3513 \nQ 3744 3084 3544 2831 \nQ 3344 2578 2956 2516 \nQ 3422 2416 3680 2098 \nQ 3938 1781 3938 1306 \nQ 3938 681 3513 340 \nQ 3088 0 2303 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-42\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-45\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" id=\"DejaVuSans-53\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-41\"/>\n       <use x=\"68.408203\" xlink:href=\"#DejaVuSans-42\"/>\n       <use x=\"137.011719\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"200.195312\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"263.671875\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"287.565625\" xlink:href=\"#m4511704269\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- RABESS -->\n      <g transform=\"translate(267.932813 239.238437)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2841 2188 \nQ 3044 2119 3236 1894 \nQ 3428 1669 3622 1275 \nL 4263 0 \nL 3584 0 \nL 2988 1197 \nQ 2756 1666 2539 1819 \nQ 2322 1972 1947 1972 \nL 1259 1972 \nL 1259 0 \nL 628 0 \nL 628 4666 \nL 2053 4666 \nQ 2853 4666 3247 4331 \nQ 3641 3997 3641 3322 \nQ 3641 2881 3436 2590 \nQ 3231 2300 2841 2188 \nz\nM 1259 4147 \nL 1259 2491 \nL 2053 2491 \nQ 2509 2491 2742 2702 \nQ 2975 2913 2975 3322 \nQ 2975 3731 2742 3939 \nQ 2509 4147 2053 4147 \nL 1259 4147 \nz\n\" id=\"DejaVuSans-52\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"65.482422\" xlink:href=\"#DejaVuSans-41\"/>\n       <use x=\"133.890625\" xlink:href=\"#DejaVuSans-42\"/>\n       <use x=\"202.494141\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"265.677734\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"329.154297\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_3\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m3d6581fcb1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3d6581fcb1\" y=\"218.63604\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 17.5 -->\n      <g transform=\"translate(7.2 222.435259)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3d6581fcb1\" y=\"190.079757\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 20.0 -->\n      <g transform=\"translate(7.2 193.878976)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3d6581fcb1\" y=\"161.523473\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 22.5 -->\n      <g transform=\"translate(7.2 165.322692)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3d6581fcb1\" y=\"132.96719\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25.0 -->\n      <g transform=\"translate(7.2 136.766409)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3d6581fcb1\" y=\"104.410906\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 27.5 -->\n      <g transform=\"translate(7.2 108.210125)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-37\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3d6581fcb1\" y=\"75.854623\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 30.0 -->\n      <g transform=\"translate(7.2 79.653842)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3d6581fcb1\" y=\"47.298339\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 32.5 -->\n      <g transform=\"translate(7.2 51.097558)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m3d6581fcb1\" y=\"18.742056\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 35.0 -->\n      <g transform=\"translate(7.2 22.541274)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-35\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 107.610625 164.13071 \nL 132.720625 164.13071 \nL 132.720625 113.858712 \nL 107.610625 113.858712 \nL 107.610625 164.13071 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 120.165625 164.13071 \nL 120.165625 208.846798 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 120.165625 113.858712 \nL 120.165625 45.827949 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 113.888125 208.846798 \nL 126.443125 208.846798 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 113.888125 45.827949 \nL 126.443125 45.827949 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m38b69e13ad\" style=\"stroke:#000000;\"/>\n    </defs>\n    <g clip-path=\"url(#pc77fa980b2)\">\n     <use style=\"fill-opacity:0;stroke:#000000;\" x=\"120.165625\" xlink:href=\"#m38b69e13ad\" y=\"17.083636\"/>\n     <use style=\"fill-opacity:0;stroke:#000000;\" x=\"120.165625\" xlink:href=\"#m38b69e13ad\" y=\"34.139138\"/>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 275.010625 173.685598 \nL 300.120625 173.685598 \nL 300.120625 131.194903 \nL 275.010625 131.194903 \nL 275.010625 173.685598 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 287.565625 173.685598 \nL 287.565625 214.756364 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 287.565625 131.194903 \nL 287.565625 74.877637 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_20\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 281.288125 214.756364 \nL 293.843125 214.756364 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 281.288125 74.877637 \nL 293.843125 74.877637 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_22\">\n    <g clip-path=\"url(#pc77fa980b2)\">\n     <use style=\"fill-opacity:0;stroke:#000000;\" x=\"287.565625\" xlink:href=\"#m38b69e13ad\" y=\"45.825296\"/>\n    </g>\n   </g>\n   <g id=\"line2d_23\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 107.610625 140.122788 \nL 132.720625 140.122788 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"line2d_24\">\n    <path clip-path=\"url(#pc77fa980b2)\" d=\"M 275.010625 150.866228 \nL 300.120625 150.866228 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc77fa980b2\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot([loss[0,:], loss[1,:]], labels = ['ABESS', 'RABESS'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the regularized best subset select (\"RABESS\" in figure)  indeed reduces the prediction error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best group subset selection\n",
    "\n",
    "Best group subset selection (BGSS) aims to choose a small part of non-overlapping groups to achieve the best interpretability on the response variable. BGSS is practically useful for the analysis of ubiquitously existing variables with certain group structures. For instance, a categorical variable with several levels is often represented by a group of dummy variables. Besides, in a nonparametric additive model, a continuous component can be represented by a set of basis functions (e.g., a linear combination of spline basis functions). Finally, specific prior knowledge can impose group structures on variables. A typical example is that the genes belonging to the same biological pathway can be considered as a group in the genomic data analysis.\n",
    "\n",
    "The BGSS can be achieved by solving:\n",
    "\n",
    "$$\n",
    "    \\min_{\\beta\\in \\mathbb{R}^p} \\frac{1}{2n} ||y-X\\beta||_2^2,\\quad s.t.\\ ||\\beta||_{0,2}\\leq s .\n",
    "$$\n",
    "\n",
    "where $||\\beta||_{0,2} = \\sum_{j=1}^J I(||\\beta_{G_j}||_2\\neq 0)$ in which $||\\cdot||_2$ is the $L_2$ norm and model size $s$ is a positive integer to be determined from data. Regardless of the NP-hard of this problem, Zhang et al develop a certifiably polynomial algorithm to solve it. This algorithm is integrated in the `abess` package, and user can handily select best group subset by assigning a proper value to the `group` arguments:\n",
    "\n",
    "We still use the dataset `dt` generated before, which has 100 samples, 5 useful variables and 15 irrelevant varibales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real coefficients:\n",
      " [  0.           0.         115.01218243   0.           0.\n",
      "  81.84924757   0.           0.           0.           0.\n",
      " 104.77568224  64.30426355   0.           0.           0.\n",
      "   0.           0.           0.         108.5408557    0.        ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('real coefficients:\\n', dt.coef_, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support we have some prior information that every 5 variables as a group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group index:\n",
      " [0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3.]\n"
     ]
    }
   ],
   "source": [
    "group = np.linspace(0, 3, 4).repeat(5)\n",
    "print('group index:\\n', group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can set the `group` argument in function. Besides, the `support_size` here indicates the number of groups, instead of the number of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficients:\n",
      " [  4.07330876  14.02654966 133.63659942  -3.25926433  -8.02172721\n",
      "   0.           0.           0.           0.           0.\n",
      "   0.           0.           0.           0.           0.\n",
      "  -4.14697258   1.53447211  16.29386214 112.43896075   8.85388996]\n"
     ]
    }
   ],
   "source": [
    "model = abessLm(support_size = range(0, 3))\n",
    "model.fit(dt.x, dt.y, group = group)\n",
    "print('coefficients:\\n', model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fitted result suggest that only two groups are selected (since `support_size` is from 0 to 2) and the selected variables are shown before.\n",
    "\n",
    "## Integrate SIS\n",
    "\n",
    "Ultra-high dimensional predictors increase computational cost but reduce estimation accuracy for any statistical procedure. To reduce dimensionality from high to a relatively acceptable level, a fairly general asymptotic framework, named feature screening (sure independence screening) is proposed to tackle even exponentially growing dimension. The feature screening can theoretically maintain all effective predictors with a high probability, which is called \"the sure screening property\".\n",
    "\n",
    "In our program, to carrying out the Integrate SIS, user need to pass an integer smaller than the number of the predictors to the `screening_size`. Then the program will first calculate the marginal likelihood of each predictor and reserve those predictors with the `screening_size` largest marginal likelihood. Then, the ABESS algorithm is conducted only on this screened subset. \n",
    "\n",
    "Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real coefficients' indexes: [243 295 659]\n",
      "fitted coefficients' indexes: [243 295 659]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "p = 1000\n",
    "k = 3\n",
    "np.random.seed(2)\n",
    "\n",
    "# gene data\n",
    "dt = make_glm_data(n = n, p = p, k = k, family = 'gaussian')\n",
    "print('real coefficients\\' indexes:', np.nonzero(dt.coef_)[0])\n",
    "\n",
    "# fit\n",
    "model = abessLm(support_size = range(0, 5), screening_size = 100)\n",
    "model.fit(dt.x, dt.y)\n",
    "print('fitted coefficients\\' indexes:', np.nonzero(model.coef_)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-specified cross validation division\n",
    "\n",
    "Sometimes, especially when running a test, we would like to fix the train and valid data used in cross validation, instead of choosing them randomly.\n",
    "One simple method is to fix a random seed, such as `numpy.random.seed()`. But in some cases, we would also like to specify which samples would be in the same \"fold\", which has great flexibility.\n",
    "\n",
    "In our program, an additional argument `cv_fold_id` is for this user-specified cross validation division. An integer array with the same size of input samples can be given, and those with same integer would be assigned to the same \"fold\" in K-fold CV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitted coefficients' indexes: [243 295 659]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "p = 1000\n",
    "k = 3\n",
    "np.random.seed(2)\n",
    "\n",
    "dt = make_glm_data(n = n, p = p, k = k, family = 'gaussian')\n",
    "\n",
    "# cv_fold_id has a size of `n`\n",
    "# cv_fold_id has `cv` different integers\n",
    "cv_fold_id = [1 for i in range(30)] + [2 for i in range(30)] + [3 for i in range(40)] \n",
    "\n",
    "model = abessLm(support_size = range(0, 5), cv = 3)\n",
    "model.fit(dt.x, dt.y, cv_fold_id = cv_fold_id)\n",
    "print('fitted coefficients\\' indexes:', np.nonzero(model.coef_)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-specified initial active set\n",
    "\n",
    "We believe that it worth allowing given an initial active set so that the splicing process starts from this set for each sparsity. \n",
    "It might come from prior analysis, whose result is not quite precise but better than random selection, so the algorithm can run more efficiently. Or you just want to give different initial sets to test the stability of the algorithm.\n",
    "\n",
    "*Note that this is NOT equal to `always_select`, since they can be exchanged to inactive set when splicing.*\n",
    "\n",
    "To specify initial active set, an additive argument `A_init` should be given in `fit()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abessLm(always_select=[], support_size=range(0, 5))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 100\n",
    "p = 10\n",
    "k = 3\n",
    "np.random.seed(2)\n",
    "\n",
    "dt = make_glm_data(n = n, p = p, k = k, family = 'gaussian')\n",
    "\n",
    "model = abessLm(support_size = range(0, 5))\n",
    "model.fit(dt.x, dt.y, A_init = [0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some strategies for initial active set are:\n",
    "\n",
    "- If $sparsity = len(A\\_init)$, the splicing process would start from $A\\_init$.\n",
    "- If $sparsity > len(A\\_init)$, the initial set includes $A\\_init$ and other variables `inital screening` chooses.\n",
    "- If $sparsity < len(A\\_init)$, the initial set includes part of $A\\_init$.\n",
    "- If both `A_init` and `always_select` are given, `always_select` first.\n",
    "- For warm-start, `A_init` will only affect splicing under the first sparsity in `support_size`.\n",
    "- For CV, `A_init` will affect each fold but not the re-fitting on full data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R tutorial\n",
    "\n",
    "For R tutorial, please view [https://abess-team.github.io/abess/articles/v07-advancedFeatures.html](https://abess-team.github.io/abess/articles/v07-advancedFeatures.html)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
