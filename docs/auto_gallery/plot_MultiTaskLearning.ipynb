{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Multi-Response Linear Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Response Linear Regression\nMultivariate multi-response linear regression (a.k.a., multi-task learning) aims at predicting multiple responses at the same time, and thus, it is a natural extension for classical linear regression where the response is univariate. \nMultivariate multi-response linear regression (MMLR) is very helpful for the analysis of correlated response such as chemical measurements for soil samples and \nmicroRNAs associated with Glioblastoma multiforme cancer. \nLet $y$ is $m$-dimensional response variable, \n$x$ is $p$-dimensional predictors, \n$B \\in R^{m \\times p}$ is coefficient matrix, \nthe MMLR model for the multivariate response is given by\n\n..math::\n  y = B x + \\epsilon,\n\nwhere $\\epsilon$ is $m$-dimensional random noise variable with zero mean. \n\nDue to the Occam`s razor principal or the high-dimensionality of predictors, it is meaningful to use a small amount of predictors to conduct multi-task learning. For example, understanding the relationship between gene expression and symptoms of a disease have significant importance in identifying potential makers. Many diseases usually involve multiple manifestations and those manifestations are usually related. In some cases, it makes sense to predict those manifestations using a small but the same set of predictors. The best subset selection problem under the MMLR model is formulated as \n\n..math::\n  \\frac{1}{2n} \\| Y - XB \\|_{2}^2, \\text{ subject to: } \\| B \\|_{0, 2} \\leq s,\n\nwhere, $Y \\in R^{n \\times m}$ and $X \\in R^{n \\times p}$ record \n$n$ observations` response and predictors, respectively. \nHere $\\| B \\|_{0, 2} = \\sum_{i = 1}^{p} I(B_{i\\cdot} = {\\bf 0})$, \nwhere $B_{i\\cdot}$ is the $i$-th row of coefficient matrix $B$ and \n${\\bf 0} \\in R^{m}$ is an all zero vector. \n\n### Simulated Data Example\nWe use an artificial dataset to demonstrate how to solve best subset selection problem for MMLR with `abess` package. \nThe `make_multivariate_glm_data()` function provides a simple way to generate suitable for this task. \nThe synthetic data have 100 observations with 3-dimensional responses and 20-dimensional predictors. Note that there are three predictors have an impact on the responses.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from abess.datasets import make_multivariate_glm_data\nimport numpy as np\nnp.random.seed(0)\n\nn = 100\np = 20\nM = 3\nk = 3\n\ndata = make_multivariate_glm_data(n = n, p = p, M = M, k = k, family = 'multigaussian')\nprint(data.y[0:5,])\n\n\nprint(data.coef_)\nprint(\"non-zero: \", set(np.nonzero(data.coef_)[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Model Fitting\nTo carry out sparse mutli-task learning, you can call the `MultiTaskRegression` like:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from abess import MultiTaskRegression\nmodel = MultiTaskRegression()\nmodel.fit(data.x, data.y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After fitting, `model.coef_` contains the predicted coefficients:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(model.coef_)\nprint(\"non-zero: \", set(np.nonzero(model.coef_)[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The outputs show that the support set is correctly identify and the parameter estimation approach to the truth.    \n\n#### More on the results\nSince there are three responses, there are three solution paths, which correspond to three responses, respectively. \nTo plot the figure, we can fix the `support_size` at different level:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\ncoef = np.zeros((3, 21, 20))\nfor s in range(21):\n    model = MultiTaskRegression(support_size = s)\n    model.fit(data.x, data.y)     \n\n    for y in range(3):\n        coef[y, s, :] = model.coef_[:, y]\n\n\n\nfor i in range(20):\n    plt.plot(coef[0, :, i])\nplt.xlabel('support_size')\nplt.ylabel('value')\nplt.title('the 1st response\\`s coefficients')\nplt.show()\n\n\n\nfor i in range(20):\n    plt.plot(coef[1, :, i])\nplt.xlabel('support_size')\nplt.ylabel('value')\nplt.title('the 2nd response\\`s coefficients')\nplt.show()\n\n\n\n\nfor i in range(20):\n    plt.plot(coef[2, :, i])\nplt.xlabel('support_size')\nplt.ylabel('value')\nplt.title('the 3rd response\\`s coefficients')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## R tutorial\nFor R tutorial, please view [https://abess-team.github.io/abess/articles/v06-MultiTaskLearning.html](https://abess-team.github.io/abess/articles/v06-MultiTaskLearning.html).\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}