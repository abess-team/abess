
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_gallery-1\Poisson_Gamma.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_gallery-1_Poisson_Gamma.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_gallery-1_Poisson_Gamma.py:


Positive response: Poisson and Gamma regression
===========================

.. GENERATED FROM PYTHON SOURCE LINES 6-21

Poisson Regression
----------------------
Poisson Regression involves regression models in which the response variable is in the form of counts. For example, the count of number of car accidents or number of costumers in line at a reception desk. The expectation of the response variables is assumed to follow a Poisson distribution.

The general mathematical equation for Poisson regression is

..math::
  \log(E(y)) = \beta_0 + \beta_1 X_1+\beta_2 X_2+\dots+\beta_p X_p.


### Simulated Data Example

We generate some artificial data using this logic.
Consider a dataset containing `n=100` observations with `p=6` variables. The `make_glm_data()` function allow you to generate simulated data. By specifying `k = 3`, here we set only 3 of the 6 variables have effect on the expectation of the response. 


.. GENERATED FROM PYTHON SOURCE LINES 21-38

.. code-block:: default


    import numpy as np
    from abess.datasets import make_glm_data
    np.random.seed(0)

    n = 100
    p = 6
    k = 3
    data = make_glm_data(n = n, p = p , k = k, family="poisson")
    print("non-zero:\n", np.nonzero(data.coef_))
    print("real coef:\n", data.coef_)



    print("the first 5 x:\n", data.x[0:5,])
    print("the first 5 y:\n",data.y[0:5])


.. GENERATED FROM PYTHON SOURCE LINES 39-42

Model Fitting
^^^^^^^^^^^^^^^^^^^^^^^ 
The `PoissonRegression()` function in the **abess** package allows you to perform best subset selection in a highly efficient way. You can call the function using formula like: 

.. GENERATED FROM PYTHON SOURCE LINES 42-49

.. code-block:: default



    from abess.linear import PoissonRegression

    model = PoissonRegression(support_size = range(7))
    model.fit(data.x, data.y)


.. GENERATED FROM PYTHON SOURCE LINES 50-51

where `support_size` contains the level of sparsity we consider, and the program can adaptively choose the "best" one. The result of coefficients can be viewed on `model.coef_`:

.. GENERATED FROM PYTHON SOURCE LINES 51-56

.. code-block:: default




    print(model.coef_)


.. GENERATED FROM PYTHON SOURCE LINES 57-62

So that the first, third and last variables are thought to be useful in the model (the chosen sparsity is 3), which is the same as "real" variables. What's more, the predicted coefficients are also close to the real ones.

More on the Results
^^^^^^^^^^^^^^^^^^^^^^^ 
Actually, we can also plot the path of coefficients in abess process. This can be computed by fitting the `support_size` in one number from 0 to 6:

.. GENERATED FROM PYTHON SOURCE LINES 62-83

.. code-block:: default




    import matplotlib.pyplot as plt

    coef = np.zeros((7, 6))
    ic = np.zeros(7)
    for s in range(7):
        model = PoissonRegression(support_size = s)
        model.fit(data.x, data.y)
        coef[s, :] = model.coef_
        ic[s] = model.ic_

    for i in range(6):
        plt.plot(coef[:, i], label = i)

    plt.xlabel('support_size')
    plt.ylabel('coefficients')
    plt.legend()
    plt.show()


.. GENERATED FROM PYTHON SOURCE LINES 84-85

And the decreasing of information criterion (by default, we use EBIC):

.. GENERATED FROM PYTHON SOURCE LINES 85-93

.. code-block:: default




    plt.plot(ic, 'o-')
    plt.xlabel('support_size')
    plt.ylabel('EBIC')
    plt.show()


.. GENERATED FROM PYTHON SOURCE LINES 94-113

The lowest point is shown on `support_size=3` and that's why the program choose 3 variables as output.

Gamma Regression
----------------------
Gamma regression can be used when you have positive continuous response variables such as payments for insurance claims, or the lifetime of a redundant system. It is well known that the density of Gamma distribution can be represented as a function of a mean parameter (:math:`\mu`) and a shape parameter (:math:`\alpha`), specifically,

..math::
  f(y \mid \mu, \alpha)=\frac{1}{y \Gamma(\alpha)}\left(\frac{\alpha y}{\mu}\right)^{\alpha} e^{-\alpha y / \mu} {I}_{(0, \infty)}(y),


where:math:`I(\cdot)` denotes the indicator function. In the Gamma regression model, response variables are assumed to follow Gamma distributions. Specifically, 

..math::
  y_i \sim Gamma(\mu_i, \alpha),


where:math:`1/\mu_i = x_i^T\beta`.

Compared with Poisson regression, this time we consider the response variables as (continuous) levels of satisfaction.

.. GENERATED FROM PYTHON SOURCE LINES 113-133

.. code-block:: default


    # Simulated Data Example
    # ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 
    # Firstly, we also generate data from `make_glm_data()`, but `family = "gamma"` is given this time:

    import numpy as np
    from abess.datasets import make_glm_data
    np.random.seed(1)

    n = 100
    p = 6
    k = 3
    data = make_glm_data(n = n, p = p , k = k, family = "gamma")
    print("non-zero:\n", np.nonzero(data.coef_))
    print("real coef:\n", data.coef_)


    print("the first 5 x:\n", data.x[0:5,])
    print("the first 5 y:\n", data.y[0:5])


.. GENERATED FROM PYTHON SOURCE LINES 134-137

Model Fitting
^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 
We apply the above procedure for gamma regression simply by using `abess.linear.GammaRegression`. It has similar member functions for fitting.

.. GENERATED FROM PYTHON SOURCE LINES 137-145

.. code-block:: default




    from abess.linear import GammaRegression

    model = GammaRegression(support_size = range(7), cv = 5) # use CV (fold = 5) for fitting
    model.fit(data.x, data.y)


.. GENERATED FROM PYTHON SOURCE LINES 146-147

The fitted coefficients:

.. GENERATED FROM PYTHON SOURCE LINES 147-152

.. code-block:: default



    print(model.coef_)



.. GENERATED FROM PYTHON SOURCE LINES 153-156

More on the Results
^^^^^^^^^^^^^^^^^^^^^^^^^^^^ 
We can also plot the path of coefficients in abess process.

.. GENERATED FROM PYTHON SOURCE LINES 156-177

.. code-block:: default




    import matplotlib.pyplot as plt

    coef = np.zeros((7, 6))
    loss = np.zeros(7)
    for s in range(7):
        model = GammaRegression(support_size = s)
        model.fit(data.x, data.y)
        coef[s, :] = model.coef_
        loss[s] = model.test_loss_

    for i in range(6):
        plt.plot(coef[:, i], label = i)

    plt.xlabel('support_size')
    plt.ylabel('coefficients')
    plt.legend()
    plt.show()


.. GENERATED FROM PYTHON SOURCE LINES 178-181

R tutorial
-------------------- 
For R tutorial, please view [https://abess-team.github.io/abess/articles/v04-PoissonGammaReg.html](https://abess-team.github.io/abess/articles/v04-PoissonGammaReg.html).


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  0.000 seconds)


.. _sphx_glr_download_auto_gallery-1_Poisson_Gamma.py:


.. only :: html

 .. container:: sphx-glr-footer
    :class: sphx-glr-footer-example



  .. container:: sphx-glr-download sphx-glr-download-python

     :download:`Download Python source code: Poisson_Gamma.py <Poisson_Gamma.py>`



  .. container:: sphx-glr-download sphx-glr-download-jupyter

     :download:`Download Jupyter notebook: Poisson_Gamma.ipynb <Poisson_Gamma.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
