<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>ABESS algorithm: details • abess</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="ABESS algorithm: details">
<meta property="og:description" content="abess">
<meta property="og:image" content="https://abess-team.github.io/abess/logo.svg">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    

    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">abess</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.4.6</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/v01-abess-guide.html">Quick start for `abess`: Linear regression</a>
    </li>
    <li>
      <a href="../articles/v03-classification.html">Classification: Logistic Regression and Multinomial Extension</a>
    </li>
    <li>
      <a href="../articles/v04-PoissonGammaReg.html">Positive response: Poisson and Gamma regression</a>
    </li>
    <li>
      <a href="../articles/v05-coxreg.html">Best Subset Selection for Censored Response</a>
    </li>
    <li>
      <a href="../articles/v06-MultiTaskLearning.html">Multi-Response Linear Regression</a>
    </li>
    <li>
      <a href="../articles/v07-advancedFeatures.html">Advanced Features</a>
    </li>
    <li>
      <a href="../articles/v08-sPCA.html">Principal component analysis</a>
    </li>
    <li>
      <a href="../articles/v09-fasterSetting.html">Tips for faster computation</a>
    </li>
    <li>
      <a href="../articles/v10-algorithm.html">ABESS algorithm: details</a>
    </li>
    <li>
      <a href="../articles/v11-power-of-abess.html">Power of abess</a>
    </li>
    <li>
      <a href="../articles/v12-Robust-Principal-Component-Analysis.html">Robust Principal Component Analysis</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/abess-team/abess/" class="external-link">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
<form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>
      
    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><script src="v10-algorithm_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>ABESS algorithm: details</h1>
                        <h4 data-toc-skip class="author">Jin Zhu, Yanhang Zhang</h4>
            
            <h4 data-toc-skip class="date">1/20/2022</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/abess-team/abess/tree/master/R-package/../vignettes/v10-algorithm.Rmd" class="external-link"><code>../vignettes/v10-algorithm.Rmd</code></a></small>
      <div class="hidden name"><code>v10-algorithm.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The ABESS algorithm employing “splicing” technique can exactly solve general best subset problem in a polynomial time. The aim of this page to provide a complete and coherent documentation for ABESS algorithm such that users can easily understand the ABESS algorithm and its variants, thereby facilitating the usage of <code>abess</code> software. We provide the details of splicing approach to linear model as follows, and its variants can be applied in similar ways.</p>
</div>
<div class="section level2">
<h2 id="linear-model">Linear model<a class="anchor" aria-label="anchor" href="#linear-model"></a>
</h2>
<div class="section level3">
<h3 id="sacrifices">Sacrifices<a class="anchor" aria-label="anchor" href="#sacrifices"></a>
</h3>
<p>Consider the <span class="math inline">\(\ell_{0}\)</span> constraint minimization problem, <span class="math display">\[
\min _{\boldsymbol{\beta}} \mathcal{L}_{n}(\boldsymbol{\beta}), \quad \text { s.t }\|\boldsymbol{\beta}\|_{0} \leq \mathrm{s},
\]</span> where $<em>{n}()=|y-X |</em>{2}^{2}. $ Without loss of generality, we consider <span class="math inline">\(\|\boldsymbol{\beta}\|_{0}=\mathrm{s}\)</span>. Given any initial set <span class="math inline">\(\mathcal{A} \subset \mathcal{S}=\{1,2, \ldots, p\}\)</span> with cardinality <span class="math inline">\(|\mathcal{A}|=s\)</span>, denote <span class="math inline">\(\mathcal{I}=\mathcal{A}^{\mathrm{c}}\)</span> and compute <span class="math display">\[
\hat{\boldsymbol{\beta}}=\arg \min _{\boldsymbol{\beta}_{\mathcal{I}}=0} \mathcal{L}_{n}(\boldsymbol{\beta}).
\]</span> We call <span class="math inline">\(\mathcal{A}\)</span> and <span class="math inline">\(\mathcal{I}\)</span> as the active set and the inactive set, respectively.</p>
<p>Given the active set <span class="math inline">\(\mathcal{A}\)</span> and <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span>, we can define the following two types of sacrifices:</p>
<ol style="list-style-type: decimal">
<li>Backward sacrifice: For any <span class="math inline">\(j \in \mathcal{A}\)</span>, the magnitude of discarding variable <span class="math inline">\(j\)</span> is, <span class="math display">\[
\xi_{j}=\mathcal{L}_{n}\left(\hat{\boldsymbol{\beta}}^{\mathcal{A} \backslash\{j\}}\right)-\mathcal{L}_{n}\left(\hat{\boldsymbol{\beta}}^{\mathcal{A}}\right)=\frac{X_{j}^{\top} X_{j}}{2 n}\left(\hat{\boldsymbol\beta}_{j}\right)^{2},
\]</span>
</li>
<li>Forward sacrifice: For any <span class="math inline">\(j \in \mathcal{I}\)</span>, the magnitude of adding variable <span class="math inline">\(j\)</span> is, <span class="math display">\[
\zeta_{j}=\mathcal{L}_{n}\left(\hat{\boldsymbol{\beta}^{\mathcal{A}}}\right)-\mathcal{L}_{n}\left(\hat{\boldsymbol{\beta}}^{\mathcal{A}}+\hat{t}^{\{j\}}\right)=\frac{X_{j}^{\top} X_{j}}{2 n}\left(\frac{\hat{\boldsymbol d}_{j}}{X_{j}^{\top} X_{j} / n}\right)^{2}.
\]</span> where <span class="math inline">\(\hat{t}=\arg \min _{t} \mathcal{L}_{n}\left(\hat{\boldsymbol{\beta}}^{\mathcal{A}}+t^{\{j\}}\right), \hat{\boldsymbol d}_{j}=X_{j}^{\top}(y-X \hat{\boldsymbol{\beta}}) / n\)</span> Intuitively, for <span class="math inline">\(j \in \mathcal{A}\)</span> (or <span class="math inline">\(j \in \mathcal{I}\)</span> ), a large <span class="math inline">\(\xi_{j}\)</span> (or <span class="math inline">\(\zeta_{j}\)</span>) implies the <span class="math inline">\(j\)</span> th variable is potentially important.</li>
</ol>
</div>
<div class="section level3">
<h3 id="algorithm">Algorithm<a class="anchor" aria-label="anchor" href="#algorithm"></a>
</h3>
<div class="section level4">
<h4 id="best-subset-selection-with-a-given-support-size">Best-Subset Selection with a Given Support Size<a class="anchor" aria-label="anchor" href="#best-subset-selection-with-a-given-support-size"></a>
</h4>
<p>Unfortunately, it is noteworthy that these two sacrifices are incomparable because they have different sizes of support set. However, if we exchange some “irrelevant” variables in <span class="math inline">\(\mathcal{A}\)</span> and some “important” variables in <span class="math inline">\(\mathcal{I}\)</span>, it may result in a higher-quality solution. This intuition motivates our splicing method. Specifically, given any splicing size <span class="math inline">\(k \leq s\)</span>, define</p>
<p><span class="math display">\[
\mathcal{A}_{k}=\left\{j \in \mathcal{A}: \sum_{i \in \mathcal{A}} \mathrm{I}\left(\xi_{j} \geq \xi_{i}\right) \leq k\right\}
\]</span> to represent <span class="math inline">\(k\)</span> least relevant variables in <span class="math inline">\(\mathcal{A}\)</span> and <span class="math display">\[
\mathcal{I}_{k}=\left\{j \in \mathcal{I}: \sum_{i \in \mathcal{I}} \mid\left(\zeta_{j} \leq \zeta_{i}\right) \leq k\right\}
\]</span> to represent <span class="math inline">\(k\)</span> most relevant variables in <span class="math inline">\(\mathcal{I} .\)</span> Then, we splice <span class="math inline">\(\mathcal{A}\)</span> and <span class="math inline">\(\mathcal{I}\)</span> by exchanging <span class="math inline">\(\mathcal{A}_{k}\)</span> and <span class="math inline">\(\mathcal{I}_{k}\)</span> and obtain a new active set <span class="math display">\[
\tilde{\mathcal{A}}=\left(\mathcal{A} \backslash \mathcal{A}_{k}\right) \cup \mathcal{I}_{k}.
\]</span> Let <span class="math inline">\(\tilde{\mathcal{I}}=\tilde{\mathcal{A}}^{c}, \tilde{\boldsymbol{\beta}}=\arg \min _{\boldsymbol{\beta}_{\overline{\mathcal{I}}}=0} \mathcal{L}_{n}(\boldsymbol{\beta})\)</span>, and <span class="math inline">\(\tau_{s}&gt;0\)</span> be a threshold. If <span class="math inline">\(\tau_{s}&lt;\)</span> <span class="math inline">\(\mathcal{L}_{n}(\hat{\boldsymbol\beta})-\mathcal{L}_{n}(\tilde{\boldsymbol\beta})\)</span>, then <span class="math inline">\(\tilde{A}\)</span> is preferable to <span class="math inline">\(\mathcal{A} .\)</span> The active set can be updated iteratively until the loss function cannot be improved by splicing. Once the algorithm recovers the true active set, we may splice some irrelevant variables, and then the loss function may decrease slightly. The threshold <span class="math inline">\(\tau_{s}\)</span> can reduce this unnecessary calculation. Typically, <span class="math inline">\(\tau_{s}\)</span> is relatively small, e.g. <span class="math inline">\(\tau_{s}=0.01 s \log (p) \log (\log n) / n.\)</span></p>
<div class="section level5">
<h5 id="algorithm-1-bess-fixs-best-subset-selection-with-a-given-support-size-s-">Algorithm 1: BESS.Fix(s): Best-Subset Selection with a given support size s.<a class="anchor" aria-label="anchor" href="#algorithm-1-bess-fixs-best-subset-selection-with-a-given-support-size-s-"></a>
</h5>
<ol style="list-style-type: decimal">
<li>Input: <span class="math inline">\(X, y\)</span>, positive integers <span class="math inline">\(k_{\max}, m_{\max}\)</span>, and a threshold <span class="math inline">\(\tau_{s}\)</span>.</li>
<li>Initialize <span class="math inline">\(\mathcal{A}^{0}=\left\{j: \sum_{i=1}^{p} \mathrm{I}\left(\left|\frac{X_{j}^{\top} y}{\sqrt{X_{j}^{\top} X_{j}}}\right| \leq \left| \frac{X_{i}^{\top} y}{\sqrt{X_{i}^{\top} X_{i}}}\right| \leq \mathrm{s}\right\}, \mathcal{I}^{0}=\left(\mathcal{A}^{0}\right)^{c}\right.\)</span>, and <span class="math inline">\(\left(\boldsymbol\beta^{0}, d^{0}\right):\)</span>
</li>
</ol>
<p><span class="math display">\[\begin{align*}
    &amp;\boldsymbol{\beta}_{\mathcal{I}^{0}}^{0}=0,\\
    &amp;d_{\mathcal{A}^{0}}^{0}=0,\\
&amp;\boldsymbol{\beta}_{\mathcal{A}^{0}}^{0}=\left(\boldsymbol{X}_{\mathcal{A}^{0}}^{\top} \boldsymbol{X}_{\mathcal{A}^{0}}\right)^{-1} \boldsymbol{X}_{\mathcal{A}^{0}}^{\top} \boldsymbol{y},\\
&amp;d_{\mathcal{I}^{0}}^{0}=X_{\mathcal{I}^{0}}^{\top}\left(\boldsymbol{y}-\boldsymbol{X} \boldsymbol{\beta}^{0}\right).
\end{align*}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>
<p>For <span class="math inline">\(m=0,1, \ldots, m_{\max}\)</span>, do</p>
<p><span class="math display">\[\left(\boldsymbol{\beta}^{m+1}, \boldsymbol{d}^{m+1}, \mathcal{A}^{m+1}, \mathcal{I}^{m+1}\right)= \text{Splicing} \left(\boldsymbol{\beta}^{m}, \boldsymbol{d}^{m}, \mathcal{A}^{m}, \mathcal{I}^{m}, k_{\max }, \tau_{s}\right).\]</span></p>
<p>If <span class="math inline">\(\left(\mathcal{A}^{m+1}, \mathcal{I}^{m+1}\right)=\left(\mathcal{A}^{m}, \mathcal{I}^{m}\right)\)</span>, then stop</p>
<p>End For</p>
</li>
<li><p>Output <span class="math inline">\((\hat{\boldsymbol{\beta}}, \hat{\boldsymbol{d}}, \hat{\mathcal{A}}, \hat{\mathcal{I}})=\left(\boldsymbol{\beta}^{m+1}, \boldsymbol{d}^{m+1} \mathcal{A}^{m+1}, \mathcal{I}^{m+1}\right).\)</span></p></li>
</ol>
</div>
<div class="section level5">
<h5 id="algorithm-2-splicing-leftboldsymbolbeta-d-mathcala-mathcali-k_max-tau_sright">Algorithm 2: Splicing <span class="math inline">\(\left(\boldsymbol\beta, d, \mathcal{A}, \mathcal{I}, k_{\max }, \tau_{s}\right)\)</span><a class="anchor" aria-label="anchor" href="#algorithm-2-splicing-leftboldsymbolbeta-d-mathcala-mathcali-k_max-tau_sright"></a>
</h5>
<ol style="list-style-type: decimal">
<li><p>Input: <span class="math inline">\(\boldsymbol{\beta}, \boldsymbol{d}, \mathcal{A}, \mathcal{I}, k_{\max }\)</span>, and <span class="math inline">\(\tau_{\mathrm{s}} .\)</span></p></li>
<li><p>Initialize <span class="math inline">\(L_{0}=L=\frac{1}{2 n}\|y-X \beta\|_{2}^{2}\)</span>, and set <span class="math inline">\(\xi_{j}=\frac{X_{j}^{\top} X_{j}}{2 n}\left(\beta_{j}\right)^{2}, \zeta_{j}=\frac{X_{j}^{\top} X_{j}}{2 n}\left(\frac{d_{j}}{X_{j}^{\top} X_{j} / n}\right)^{2}, j=1, \ldots, p.\)</span></p></li>
<li>
<p>For <span class="math inline">\(k=1,2, \ldots, k_{\max }\)</span>, do</p>
<p><span class="math display">\[\mathcal{A}_{k}=\left\{j \in \mathcal{A}: \sum_{i \in \mathcal{A}} \mathrm{I}\left(\xi_{j} \geq \xi_{i}\right) \leq k\right\}\]</span></p>
<p><span class="math display">\[\mathcal{I}_{k}=\left\{j \in \mathcal{I}: \sum_{i \in \mathcal{I}} \mathrm{I}\left(\zeta_{j} \leq \zeta_{i}\right) \leq k\right\}\]</span></p>
<p>Let <span class="math inline">\(\tilde{\mathcal{A}}_{k}=\left(\mathcal{A} \backslash \mathcal{A}_{k}\right) \cup \mathcal{I}_{k}, \tilde{\mathcal{I}}_{k}=\left(\mathcal{I} \backslash \mathcal{I}_{k}\right) \cup \mathcal{A}_{k}\)</span> and solve</p>
<p><span class="math display">\[\tilde{\boldsymbol{\beta}}_{{\mathcal{A}}_{k}}=\left(\boldsymbol{X}_{\mathcal{A}_{k}}^{\top} \boldsymbol{X}_{{\mathcal{A}}_{k}}\right)^{-1} \boldsymbol{X}_{{\mathcal{A}_{k}}}^{\top} y, \quad \tilde{\boldsymbol{\beta}}_{{\mathcal{I}}_{k}}=0\]</span></p>
<p><span class="math display">\[\tilde{\boldsymbol d}_{\mathcal{I}^k}=X_{\mathcal{I}^k}^{\top}(y-X \tilde{\beta}) / n,\quad \tilde{\boldsymbol d}_{\mathcal{A}^k} = 0.\]</span></p>
<p>Compute <span class="math inline">\(\mathcal{L}_{n}(\tilde{\boldsymbol\beta})=\frac{1}{2 n}\|y-X \tilde{\boldsymbol\beta}\|_{2}^{2}.\)</span></p>
<p>If <span class="math inline">\(L&gt;\mathcal{L}_{n}(\tilde{\boldsymbol\beta})\)</span>, then</p>
<p><span class="math display">\[(\hat{\boldsymbol{\beta}}, \hat{\boldsymbol{d}}, \hat{\mathcal{A}}, \hat{\mathcal{I}})=\left(\tilde{\boldsymbol{\beta}}, \tilde{\boldsymbol{d}}, \tilde{\mathcal{A}}_{k}, \tilde{\mathcal{I}}_{k}\right)\]</span></p>
<p><span class="math display">\[L=\mathcal{L}_{n}(\tilde{\boldsymbol\beta}).\]</span></p>
<p>End for</p>
</li>
<li><p>If <span class="math inline">\(L_{0}-L&lt;\tau_{s}\)</span>, then <span class="math inline">\((\hat{\boldsymbol\beta}, \hat{d}, \hat{A}, \hat{I})=(\boldsymbol\beta, d, \mathcal{A}, \mathcal{I}).\)</span></p></li>
<li><p>Output <span class="math inline">\((\hat{\boldsymbol{\beta}}, \hat{\boldsymbol{d}}, \hat{\mathcal{A}}, \hat{\mathcal{I}})\)</span>.</p></li>
</ol>
<!-- In practice, the support size is usually unknown. We use a data-driven procedure to determine s. Information criteria such as highdimensional BIC (HBIC) (13) and extended BIC (EBIC) (14) are commonly used for this purpose. Specifically, HBIC (13) can be applied to select the tuning parameter in penalized likelihood estimation. To recover the support size $s$ for the best-subset selection, we introduce a criterion that is a special case of HBIC (13). While HBIC aims to tune the parameter for a nonconvex penalized regression, our proposal is used to determine the size of best subset. For any active set $\mathcal{A}$, define an $\mathrm{SIC}$ as follows: --><!-- $$ --><!-- \operatorname{SIC}(\mathcal{A})=n \log \mathcal{L}_{\mathcal{A}}+|\mathcal{A}| \log (p) \log \log n, --><!-- $$ --><!-- where $\mathcal{L}_{\mathcal{A}}=\min _{\beta_{\mathcal{I}}=0} \mathcal{L}_{n}(\beta), \mathcal{I}=(\mathcal{A})^{c}$. To identify the true model, the --><!-- model complexity penalty is $\log p$ and the slow diverging rate $\log \log n$ is set to prevent underfitting. Theorem 4 states that the following ABESS algorithm selects the true support size via SIC. --><!-- Let $s_{\max }$ be the maximum support size. Theorem 4 suggests $s_{\max }=o\left(\frac{n}{\log p}\right)$ as the maximum possible recovery size. Typically, we set $s_{\max }=\left[\frac{n}{\log (p) \log \log n}\right]$ --><!-- where $[x]$ denotes the integer part of $x$. -->
</div>
</div>
<div class="section level4">
<h4 id="determining-the-best-support-size-with-sic">Determining the Best Support Size with SIC<a class="anchor" aria-label="anchor" href="#determining-the-best-support-size-with-sic"></a>
</h4>
<p>In practice, the support size is usually unknown. We use a data-driven procedure to determine s. For any active set <span class="math inline">\(\mathcal{A}\)</span>, define an <span class="math inline">\(\mathrm{SIC}\)</span> as follows: <span class="math display">\[
\operatorname{SIC}(\mathcal{A})=n \log \mathcal{L}_{\mathcal{A}}+|\mathcal{A}| \log (p) \log \log n,
\]</span> where <span class="math inline">\(\mathcal{L}_{\mathcal{A}}=\min _{\beta_{\mathcal{I}}=0} \mathcal{L}_{n}(\beta), \mathcal{I}=(\mathcal{A})^{c}\)</span>. To identify the true model, the model complexity penalty is <span class="math inline">\(\log p\)</span> and the slow diverging rate <span class="math inline">\(\log \log n\)</span> is set to prevent underfitting. Theorem 4 states that the following ABESS algorithm selects the true support size via SIC.</p>
<p>Let <span class="math inline">\(s_{\max }\)</span> be the maximum support size. We suggest <span class="math inline">\(s_{\max }=o\left(\frac{n}{\log p}\right)\)</span> as the maximum possible recovery size. Typically, we set <span class="math inline">\(s_{\max }=\left[\frac{n}{\log (p) \log \log n}\right]\)</span> where <span class="math inline">\([x]\)</span> denotes the integer part of <span class="math inline">\(x\)</span>.</p>
<div class="section level5">
<h5 id="algorithm-3-abess-">Algorithm 3: ABESS.<a class="anchor" aria-label="anchor" href="#algorithm-3-abess-"></a>
</h5>
<ol style="list-style-type: decimal">
<li><p>Input: <span class="math inline">\(X, y\)</span>, and the maximum support size <span class="math inline">\(s_{\max } .\)</span></p></li>
<li>
<p>For <span class="math inline">\(s=1,2, \ldots, s_{\max }\)</span>, do</p>
<p><span class="math display">\[\left(\hat{\boldsymbol{\beta}}_{s}, \hat{\boldsymbol{d}}_{s}, \hat{\mathcal{A}}_{s}, \hat{\mathcal{I}}_{s}\right)= \text{BESS.Fixed}(s).\]</span></p>
<p>End for</p>
</li>
<li>
<p>Compute the minimum of SIC:</p>
<p><span class="math display">\[s_{\min }=\arg \min _{s} \operatorname{SIC}\left(\hat{\mathcal{A}}_{s}\right).\]</span></p>
</li>
<li><p>Output <span class="math inline">\(\left(\hat{\boldsymbol{\beta}}_{s_{\operatorname{min}}}, \hat{\boldsymbol{d}}_{s_{\min }}, \hat{A}_{s_{\min }}, \hat{\mathcal{I}}_{s_{\min }}\right) .\)</span></p></li>
</ol>
<!-- # Group linear model --><!-- Group linear model is a linear model which the $p$ predictors are separated into $J$ pre-determined non-overlapping groups, --><!-- $$ --><!-- y = \sum_{j=1}^J X_{G_i} \boldsymbol{\beta_{G_j}}+\epsilon. --><!-- $$ --><!-- Consider the quadratic minimization problem with $\ell_{0,2}$ constraint, --><!-- $$ --><!-- \min _{\boldsymbol{{\boldsymbol\beta}}} \mathcal{L_n}({\boldsymbol\beta}), \quad \text { s.t }\|{{\boldsymbol\beta}}\|_{0,2} \leq \mathrm{s}, --><!-- $$ --><!-- where the $\ell_{0,2}$ (-pseudo) norm is defined as $\|{{\boldsymbol\beta}}\|_{0,2} = \sum_{j=1}^J \mathrm{I} (\|\boldsymbol{\beta_{G_j}}\|_2 \neq 0)$. --><!-- # Nuisance selection --><!-- # Principal component analysis -->
</div>
</div>
</div>
</div>
<div class="section level2">
<h2 id="the-corresponding-notations-in-abess-function">The corresponding notations in <code>abess()</code> function<a class="anchor" aria-label="anchor" href="#the-corresponding-notations-in-abess-function"></a>
</h2>
<table class="table">
<colgroup>
<col width="33%">
<col width="33%">
<col width="33%">
</colgroup>
<thead><tr class="header">
<th align="left">Notations in algorithm</th>
<th align="left">Parameters in <span class="math inline">\(\mathtt{abess}\)</span>
</th>
<th align="left">Definitions</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(m_{\max}\)</span></td>
<td align="left">max.splicing.iter</td>
<td align="left">The maximum number of splicing algorithm</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(k_{\max}\)</span></td>
<td align="left">c.max</td>
<td align="left">The maximum splicing size</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(1,\ldots,s_{\max}\)</span></td>
<td align="left">support.size</td>
<td align="left">A sequence representing the support sizes</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\operatorname{SIC}\)</span></td>
<td align="left">tune.type</td>
<td align="left">The type of criterion for choosing the support size</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\{G_1, \ldots, G_J\}\)</span></td>
<td align="left">group.index</td>
<td align="left">A vector indicator the group that each variable belongs to</td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\lambda\)</span></td>
<td align="left">lambda</td>
<td align="left">A value for regularized best subset selection</td>
</tr>
<tr class="odd">
<td align="left">Golden-section searching</td>
<td align="left">gs.range</td>
<td align="left">Upper and lower bounds of the search range</td>
</tr>
</tbody>
</table>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Jin Zhu, Liyuan Hu, Junhao Huang, Kangkang Jiang, Yanhang Zhang, Zezhi Wang, Borui Tang, Shiyun Lin, Junxian Zhu, Canhong Wen, Heping Zhang, Xueqin Wang.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

      </footer>
</div>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({
    
    
    apiKey: 'd32715b0e35635336aba6377dd751e21',
    indexName: 'abess',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
