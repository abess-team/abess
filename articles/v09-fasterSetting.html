<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Tips for faster computation • abess</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><!-- docsearch --><script src="../docsearch.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.3/docsearch.min.css" integrity="sha256-QOSRU/ra9ActyXkIBbiIB144aDBdtvXBcNc3OTNuX/Q=" crossorigin="anonymous">
<link href="../docsearch.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script><meta property="og:title" content="Tips for faster computation">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">


    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">abess</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.4.9</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/v01-abess-guide.html">Quick start for `abess`: Linear regression</a>
    </li>
    <li>
      <a href="../articles/v03-classification.html">Classification: Logistic Regression and Multinomial Extension</a>
    </li>
    <li>
      <a href="../articles/v04-PoissonGammaReg.html">Positive response: Poisson and Gamma regression</a>
    </li>
    <li>
      <a href="../articles/v05-coxreg.html">Best Subset Selection for Censored Response</a>
    </li>
    <li>
      <a href="../articles/v06-MultiTaskLearning.html">Multi-Response Linear Regression</a>
    </li>
    <li>
      <a href="../articles/v07-advancedFeatures.html">Advanced Features</a>
    </li>
    <li>
      <a href="../articles/v08-sPCA.html">Principal component analysis</a>
    </li>
    <li>
      <a href="../articles/v09-fasterSetting.html">Tips for faster computation</a>
    </li>
    <li>
      <a href="../articles/v10-algorithm.html">ABESS algorithm: details</a>
    </li>
    <li>
      <a href="../articles/v11-power-of-abess.html">Power of abess</a>
    </li>
    <li>
      <a href="../articles/v12-Robust-Principal-Component-Analysis.html">Robust Principal Component Analysis</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/abess-team/abess/" class="external-link">
    <span class="fab fa-github fa-lg"></span>

  </a>
</li>
      </ul>
<form class="navbar-form navbar-right hidden-xs hidden-sm" role="search">
        <div class="form-group">
          <input type="search" class="form-control" name="search-input" id="search-input" placeholder="Search..." aria-label="Search for..." autocomplete="off">
</div>
      </form>

    </div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Tips for faster computation</h1>
                        <h4 data-toc-skip class="author">Jin Zhu</h4>
            
            <h4 data-toc-skip class="date">6/13/2021</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/abess-team/abess/tree/master/R-package/vignettes/v09-fasterSetting.Rmd" class="external-link"><code>vignettes/v09-fasterSetting.Rmd</code></a></small>
      <div class="hidden name"><code>v09-fasterSetting.Rmd</code></div>

    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The generic splicing technique certifiably guarantees the best subset
can be selected in a polynomial time. In practice, the computational
efficiency can be improved to handle large scale datasets. The tips for
computational improvement include:</p>
<ul>
<li>exploit sparse structure of input matrix;</li>
<li>use golden-section to search best support size;<br>
</li>
<li>early-stop scheme;<br>
</li>
<li>sure independence screening;<br>
</li>
<li>warm-start initialization;<br>
</li>
<li>parallel computing when performing cross validation;<br>
</li>
<li>covariance update for <code>family = "gaussian"</code> or
<code>family = "mgaussian"</code>;<br>
</li>
<li>approximate Newton iteration for <code>family = "binomial"</code>,
<code>family = "poisson"</code>, <code>family = "cox"</code>.</li>
</ul>
<p>This vignette illustrate the first three tips. For the other tips,
they have been efficiently implemented and set as the default in abess
package.</p>
</div>
<div class="section level2">
<h2 id="sparse-matrix">Sparse matrix<a class="anchor" aria-label="anchor" href="#sparse-matrix"></a>
</h2>
<p>We sometimes meet with problems where the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo>×</mo><mi>p</mi></mrow><annotation encoding="application/x-tex">N \times p</annotation></semantics></math>
input matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
is extremely sparse, i.e., many entries in
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
have zero values. A notable example comes from document classification:
aiming to assign classes to a document, making it easier to manage for
publishers and news sites. The input variables for characterizing
documents are generated from a so called ``bag-of-words’’ model. In this
model, each variable is scored for the presence of each of the words in
the entire dictionary under consideration. Since most words are absent,
the input variables for each document is mostly zero, and so the entire
matrix is mostly zero. Such sparse matrices can be efficiently stored in
R with a <em>sparse column format</em> via the <a href="https://cran.r-project.org/web/packages/Matrix" class="external-link">Matrix</a>
package. And the sparse matrix can be directly used by our
<strong>abess</strong> package for boosting the computational
efficient.</p>
<p>ABESS algorithm is ideally set up to exploit such sparsity. The
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>N</mi><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math>
inner-product operations when computing forward sacrifice can exploit
the sparsity, by summing over only the non-zero entries. For computing
backward sacrifice, the sparsity also facilitate solving the convex
optimization under a given support set. The following example
demonstrates the efficiency gain from the sparse matrix. We first
generate a input matrix whose 90% entries are 0.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://Matrix.R-forge.R-project.org" class="external-link">Matrix</a></span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## Loading required package: Matrix</span></span></code></pre>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">num</span> <span class="op">&lt;-</span> <span class="fl">1000</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">100</span></span>
<span><span class="va">sparse_ratio</span> <span class="op">&lt;-</span> <span class="fl">0.9</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">num</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">num</span><span class="op">)</span></span>
<span><span class="va">zero_entry</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html" class="external-link">rbinom</a></span><span class="op">(</span><span class="va">num</span> <span class="op">*</span> <span class="va">p</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="va">sparse_ratio</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">num</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">[</span><span class="va">zero_entry</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">x</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">5</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span> <span class="op">-</span> <span class="fl">5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/Matrix/man/Matrix.html" class="external-link">Matrix</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">10</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## 6 x 10 sparse Matrix of class "dgCMatrix"</span></span>
<span><span class="co">##                                               </span></span>
<span><span class="co">## [1,] . . . 1.120616 . . .       . .          .</span></span>
<span><span class="co">## [2,] . . . .        . . .       . .          .</span></span>
<span><span class="co">## [3,] . . . .        . . .       . .          .</span></span>
<span><span class="co">## [4,] . . . .        . . .       . .          .</span></span>
<span><span class="co">## [5,] . . . .        . . .       . 0.09618829 .</span></span>
<span><span class="co">## [6,] . . . .        . . 1.12201 . .          .</span></span></code></pre>
<p>Then, we apply ABESS algorithm on Matrix <code>x</code> and record
the runtime in <code>t1</code>:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/abess-team/abess" class="external-link">abess</a></span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">##  Thank you for using abess! To acknowledge our work, please cite the package:</span></span></code></pre>
<pre><code><span><span class="co">## </span></span>
<span><span class="co">##  Zhu J, Wang X, Hu L, Huang J, Jiang K, Zhang Y, Lin S, Zhu J (2022). 'abess: A Fast Best Subset Selection Library in Python and R.' Journal of Machine Learning Research, 23(202), 1-7. https://www.jmlr.org/papers/v23/21-1060.html.</span></span></code></pre>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">t1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span><span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.html">abess</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>We compare the runtime when the input matrix is dense matrix:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">as.matrix</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">x</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">]</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">##      [,1] [,2] [,3]     [,4] [,5] [,6]</span></span>
<span><span class="co">## [1,]    0    0    0 1.120616    0    0</span></span>
<span><span class="co">## [2,]    0    0    0 0.000000    0    0</span></span>
<span><span class="co">## [3,]    0    0    0 0.000000    0    0</span></span>
<span><span class="co">## [4,]    0    0    0 0.000000    0    0</span></span>
<span><span class="co">## [5,]    0    0    0 0.000000    0    0</span></span>
<span><span class="co">## [6,]    0    0    0 0.000000    0    0</span></span></code></pre>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">t2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span><span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.html">abess</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">t1</span>, <span class="va">t2</span><span class="op">)</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##    user.self sys.self elapsed</span></span>
<span><span class="co">## t1     0.138    0.000   0.138</span></span>
<span><span class="co">## t2     0.116    0.002   0.119</span></span></code></pre>
<p>From the comparison, we see that the time required by sparse matrix
is visibly smaller, and thus, we suggest to assign a sparse matrix to
<code>abess</code> when the input matrix have a lot of zero entries.</p>
</div>
<div class="section level2">
<h2 id="golden-section-searching">Golden-section searching<a class="anchor" aria-label="anchor" href="#golden-section-searching"></a>
</h2>
<p>The following is a typical ``model size v.s. BGIC’’ plot.<br><img src="sgsplicing.png" style="width:80.0%"></p>
<p>The
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>x</mi><annotation encoding="application/x-tex">x</annotation></semantics></math>-axis
is model size, and the
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>y</mi><annotation encoding="application/x-tex">y</annotation></semantics></math>-axis
is BGIC’s value recorded in group splicing algorithm for linear model.
The entries of design matrix
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math>
are <em>i.i.d.</em> sampled from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒩</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{N}(0, 1)</annotation></semantics></math>,
and the matrix shape is
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn><mo>×</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">100 \times 200</annotation></semantics></math>.
The error term
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>ε</mi><annotation encoding="application/x-tex">\varepsilon</annotation></semantics></math>
are <em>i.i.d.</em>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>𝒩</mi><mrow><mo stretchy="true" form="prefix">(</mo><mn>0</mn><mo>,</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\mathcal{N}(0, \frac{1}{2})</annotation></semantics></math>.
Take the two adjacent variables as one group, and set the true
coefficients
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mn>1</mn><mo>,</mo><mo>−</mo><mn>1</mn><mo>,</mo><mo>−</mo><mn>1</mn><mo>,</mo><mo>−</mo><mn>1</mn><mo>,</mo><mo>−</mo><mn>1</mn><mo>,</mo><mn>0</mn><mo>,</mo><mi>…</mi><mo>,</mo><mn>0</mn><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">\beta=(1, 1, 1, 1, 1, 1, -1, -1, -1, -1, 0, \ldots, 0)</annotation></semantics></math>.
The orange vertical dash line indicates the true group subset size.</p>
<p>From this Figure, we see that the BGIC decreases from
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">T=1</annotation></semantics></math>
to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">T=5</annotation></semantics></math>,
but it increases as
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>T</mi><annotation encoding="application/x-tex">T</annotation></semantics></math>
larger than
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>5</mn><annotation encoding="application/x-tex">5</annotation></semantics></math>.
In other words, the BGIC path of SGSplicing algorithm is a strictly
unimodal function achieving minimum at the true group subset size
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo>=</mo><mn>5</mn></mrow><annotation encoding="application/x-tex">T = 5</annotation></semantics></math>.
Motivated by this observation, we suggest to recruit a heuristic search
based on the golden-section search technique, an efficient method for
finding the extremum of a unimodal function, to determine support size
that minimizing BGIC. Compared with searching the optimal support size
one by one from a candidate set with
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>s</mi><mo>max</mo></msub><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(s_{\max})</annotation></semantics></math>
complexity, golden-section reduce the time complexity to
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><mo>ln</mo><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>s</mi><mo>max</mo></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(\ln{(s_{\max})})</annotation></semantics></math>,
giving a significant computational improvement.</p>
<p>The code below exhibits how to employ the golden search technique
with abess package:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">synthetic_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/generate.data.html">generate.data</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">500</span>, p <span class="op">=</span> <span class="fl">100</span>, </span>
<span>                                beta <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">3</span>, <span class="fl">1.5</span>, <span class="fl">0</span>, <span class="fl">0</span>, <span class="fl">2</span>, <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">95</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">dat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind.data.frame</a></span><span class="op">(</span><span class="st">"y"</span> <span class="op">=</span> <span class="va">synthetic_data</span><span class="op">[[</span><span class="st">"y"</span><span class="op">]</span><span class="op">]</span>, </span>
<span>                        <span class="va">synthetic_data</span><span class="op">[[</span><span class="st">"x"</span><span class="op">]</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="va">t1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span><span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.html">abess</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">dat</span>, tune.path <span class="op">=</span> <span class="st">"gsection"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="fu"><a href="../reference/extract.abess.html">extract</a></span><span class="op">(</span><span class="va">abess_fit</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">## List of 7</span></span>
<span><span class="co">##  $ beta        :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots</span></span>
<span><span class="co">##   .. ..@ i       : int [1:3] 0 1 4</span></span>
<span><span class="co">##   .. ..@ p       : int [1:2] 0 3</span></span>
<span><span class="co">##   .. ..@ Dim     : int [1:2] 100 1</span></span>
<span><span class="co">##   .. ..@ Dimnames:List of 2</span></span>
<span><span class="co">##   .. .. ..$ : chr [1:100] "x1" "x2" "x3" "x4" ...</span></span>
<span><span class="co">##   .. .. ..$ : chr "3"</span></span>
<span><span class="co">##   .. ..@ x       : num [1:3] 3.04 1.49 1.91</span></span>
<span><span class="co">##   .. ..@ factors : list()</span></span>
<span><span class="co">##  $ intercept   : num -0.0679</span></span>
<span><span class="co">##  $ support.size: int 3</span></span>
<span><span class="co">##  $ support.vars: chr [1:3] "x1" "x2" "x5"</span></span>
<span><span class="co">##  $ support.beta: num [1:3] 3.04 1.49 1.91</span></span>
<span><span class="co">##  $ dev         : num 0.745</span></span>
<span><span class="co">##  $ tune.value  : num -122</span></span></code></pre>
<p>The output of golden-section strategy suggests the optimal model size
is accurately detected. Compare to the sequential searching, the golden
section reduce the runtime because it skip some support sizes which are
likely to be a non-optimal one:</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">t2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span><span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.html">abess</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">t1</span>, <span class="va">t2</span><span class="op">)</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##    user.self sys.self elapsed</span></span>
<span><span class="co">## t1     0.006    0.000   0.007</span></span>
<span><span class="co">## t2     0.022    0.001   0.022</span></span></code></pre>
</div>
<div class="section level2">
<h2 id="early-stop">Early stop<a class="anchor" aria-label="anchor" href="#early-stop"></a>
</h2>
<p>In machine learning, early stopping is a helpful strategy not only
avoid overfitting but also reducing training time. For the
early-stopping implementation in abess, validation is used to detect
when overfitting starts during performing adaptive best subset
selection; training is then stopped even though the best subset under
certain larger support size haven’t found. We give an example to
demonstrate the helpfulness of early stopping in decreasing runtimes.
(Do not finish, the early stopping do not available in cpp)</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">t1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span><span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.html">abess</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">dat</span>, early.stop <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">abess_fit</span></span></code></pre></div>
<pre><code><span><span class="co">## Call:</span></span>
<span><span class="co">## abess.formula(formula = y ~ ., data = dat, early.stop = TRUE)</span></span>
<span><span class="co">## </span></span>
<span><span class="co">##    support.size       dev         GIC</span></span>
<span><span class="co">## 1             0 8.6400493 1078.204142</span></span>
<span><span class="co">## 2             1 3.8958639  688.370921</span></span>
<span><span class="co">## 3             2 1.9816733  358.797191</span></span>
<span><span class="co">## 4             3 0.7451024 -121.877226</span></span>
<span><span class="co">## 5             4 0.7337883 -121.114561</span></span>
<span><span class="co">## 6             5 0.7229702 -120.127663</span></span>
<span><span class="co">## 7             6 0.7163121 -116.340488</span></span>
<span><span class="co">## 8             7 0.7091789 -112.931327</span></span>
<span><span class="co">## 9             8 0.7024621 -109.276323</span></span>
<span><span class="co">## 10            9 0.6976621 -104.291399</span></span>
<span><span class="co">## 11           10 0.6932543  -99.047213</span></span>
<span><span class="co">## 12           11 0.6892982  -93.495441</span></span>
<span><span class="co">## 13           12 0.6846565  -88.460620</span></span>
<span><span class="co">## 14           13 0.6810295  -82.703248</span></span>
<span><span class="co">## 15           14 0.6772793  -77.051013</span></span>
<span><span class="co">## 16           15 0.6741793  -70.931592</span></span>
<span><span class="co">## 17           16 0.6710871  -64.817014</span></span>
<span><span class="co">## 18           17 0.6682440  -58.526563</span></span>
<span><span class="co">## 19           18 0.6653608  -52.275367</span></span>
<span><span class="co">## 20           19 0.6628664  -45.740178</span></span>
<span><span class="co">## 21           20 0.6603517  -39.227384</span></span>
<span><span class="co">## 22           21 0.6578908  -32.681006</span></span>
<span><span class="co">## 23           22 0.6555246  -26.069380</span></span>
<span><span class="co">## 24           23 0.6535097  -19.195392</span></span>
<span><span class="co">## 25           24 0.6515939  -12.250127</span></span>
<span><span class="co">## 26           25 0.6494848   -5.457983</span></span>
<span><span class="co">## 27           26 0.6476394    1.532509</span></span>
<span><span class="co">## 28           27 0.6457393    8.476659</span></span>
<span><span class="co">## 29           28 0.6438120   15.395256</span></span>
<span><span class="co">## 30           29 0.6418701   22.298056</span></span>
<span><span class="co">## 31           30 0.6397735   29.075429</span></span>
<span><span class="co">## 32           31 0.6380951   36.175194</span></span>
<span><span class="co">## 33           32 0.6363094   43.187138</span></span>
<span><span class="co">## 34           33 0.6345171   50.189989</span></span>
<span><span class="co">## 35           34 0.6327394   57.200441</span></span>
<span><span class="co">## 36           35 0.6310138   64.248152</span></span>
<span><span class="co">## 37           36 0.6294229   71.399182</span></span>
<span><span class="co">## 38           37 0.6278000   78.521521</span></span>
<span><span class="co">## 39           38 0.6264222   85.836180</span></span>
<span><span class="co">## 40           39 0.6242619   92.522044</span></span>
<span><span class="co">## 41           40 0.6223307   99.386095</span></span>
<span><span class="co">## 42           41 0.6210093  106.736478</span></span>
<span><span class="co">## 43           42 0.6197906  114.167492</span></span>
<span><span class="co">## 44           43 0.6185396  121.570460</span></span>
<span><span class="co">## 45           44 0.6172515  128.941329</span></span>
<span><span class="co">## 46           45 0.6159546  136.302901</span></span>
<span><span class="co">## 47           46 0.6147094  143.704246</span></span>
<span><span class="co">## 48           47 0.6137414  151.329447</span></span>
<span><span class="co">## 49           48 0.6127953  158.971283</span></span>
<span><span class="co">## 50           49 0.6118767  166.634416</span></span>
<span><span class="co">## 51           50 0.6110400  174.363418</span></span>
<span><span class="co">## 52           51 0.6101414  182.040795</span></span>
<span><span class="co">## 53           52 0.6094084  189.853000</span></span>
<span><span class="co">## 54           53 0.6086294  197.626589</span></span>
<span><span class="co">## 55           54 0.6077610  205.325872</span></span>
<span><span class="co">## 56           55 0.6070552  213.158128</span></span>
<span><span class="co">## 57           56 0.6062506  220.908182</span></span>
<span><span class="co">## 58           57 0.6054073  228.625357</span></span>
<span><span class="co">## 59           58 0.6046684  236.427918</span></span>
<span><span class="co">## 60           59 0.6039253  244.226313</span></span></code></pre>
<p>We can see that ABESS algorithm stop when support size is 4. This is
because the GIC value (can be considered as an assessment in validation
set) do not increase when support size reach to 3, and thus, the program
early terminate. This result is match to our simulation setting. Compare
with the ABESS without early-stopping:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">t2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/system.time.html" class="external-link">system.time</a></span><span class="op">(</span><span class="va">abess_fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/abess.html">abess</a></span><span class="op">(</span><span class="va">y</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">dat</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">rbind</a></span><span class="op">(</span><span class="va">t1</span>, <span class="va">t2</span><span class="op">)</span><span class="op">[</span>, <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">]</span></span></code></pre></div>
<pre><code><span><span class="co">##    user.self sys.self elapsed</span></span>
<span><span class="co">## t1     0.022    0.001   0.022</span></span>
<span><span class="co">## t2     0.022    0.001   0.022</span></span></code></pre>
<p>we can conclude that early-stopping brings fast computation and might
maintain statistical guarantee.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

      </div>

</div>



      <footer><div class="copyright">
  <p></p>
<p>Developed by Jin Zhu, Zezhi Wang, Liyuan Hu, Junhao Huang, Kangkang Jiang, Yanhang Zhang, Borui Tang, Shiyun Lin, Junxian Zhu, Canhong Wen, Heping Zhang, Xueqin Wang.</p>
</div>

<div class="pkgdown">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

      </footer>
</div>


<script src="https://cdnjs.cloudflare.com/ajax/libs/docsearch.js/2.6.1/docsearch.min.js" integrity="sha256-GKvGqXDznoRYHCwKXGnuchvKSwmx9SRMrZOTh2g4Sb0=" crossorigin="anonymous"></script><script>
  docsearch({


    apiKey: 'd32715b0e35635336aba6377dd751e21',
    indexName: 'abess',
    inputSelector: 'input#search-input.form-control',
    transformData: function(hits) {
      return hits.map(function (hit) {
        hit.url = updateHitURL(hit);
        return hit;
      });
    }
  });
</script>
</body>
</html>
