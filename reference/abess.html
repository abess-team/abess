<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Adaptive Best-Subset Selection via Splicing — abess.default • abess</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://cdnjs.cloudflare.com/ajax/libs/bootswatch/3.4.0/cerulean/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous" />


<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="Adaptive Best-Subset Selection via Splicing — abess.default" />
<meta property="og:description" content="Adaptive best-subset selection for regression, 
classification, counting-response, censored-response, multi-response modeling 
in polynomial times." />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">abess</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">0.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/v01-abess-guide.html">Quick start for `abess`: Linear regression</a>
    </li>
    <li>
      <a href="../articles/v03-classification.html">Classification: Logistic Regression and Multinomial Extension</a>
    </li>
    <li>
      <a href="../articles/v04-poissonregression.html">Poisson Regression</a>
    </li>
    <li>
      <a href="../articles/v05-coxreg.html">Best Subset Selection for Censored Response</a>
    </li>
    <li>
      <a href="../articles/v06-MultiTaskLearning.html">Multi-Response Linear Regression</a>
    </li>
    <li>
      <a href="../articles/v07-advancedFeatures.html">Advanced Features</a>
    </li>
    <li>
      <a href="../articles/v08-sPCA.html">Principal component analysis</a>
    </li>
    <li>
      <a href="../articles/v09-fasterSetting.html">Tips for faster computation</a>
    </li>
    <li>
      <a href="../articles/v10-algorithm.html">ABESS algorithm: details</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/abess-team/abess/">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Adaptive Best-Subset Selection via Splicing</h1>
    <small class="dont-index">Source: <a href='https://github.com/abess-team/abess/blob/master/R/abess.R'><code>R/abess.R</code></a></small>
    <div class="hidden name"><code>abess.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Adaptive best-subset selection for regression, 
classification, counting-response, censored-response, multi-response modeling 
in polynomial times.</p>
    </div>

    <pre class="usage"><span class='co'># S3 method for default</span>
<span class='fu'>abess</span><span class='op'>(</span>
  <span class='va'>x</span>,
  <span class='va'>y</span>,
  family <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"gaussian"</span>, <span class='st'>"binomial"</span>, <span class='st'>"poisson"</span>, <span class='st'>"cox"</span>, <span class='st'>"mgaussian"</span>, <span class='st'>"multinomial"</span><span class='op'>)</span>,
  tune.path <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"sequence"</span>, <span class='st'>"gsection"</span><span class='op'>)</span>,
  tune.type <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"gic"</span>, <span class='st'>"ebic"</span>, <span class='st'>"bic"</span>, <span class='st'>"aic"</span>, <span class='st'>"cv"</span><span class='op'>)</span>,
  weight <span class='op'>=</span> <span class='cn'>NULL</span>,
  normalize <span class='op'>=</span> <span class='cn'>NULL</span>,
  c.max <span class='op'>=</span> <span class='fl'>2</span>,
  support.size <span class='op'>=</span> <span class='cn'>NULL</span>,
  gs.range <span class='op'>=</span> <span class='cn'>NULL</span>,
  lambda <span class='op'>=</span> <span class='fl'>0</span>,
  always.include <span class='op'>=</span> <span class='cn'>NULL</span>,
  group.index <span class='op'>=</span> <span class='cn'>NULL</span>,
  splicing.type <span class='op'>=</span> <span class='fl'>2</span>,
  max.splicing.iter <span class='op'>=</span> <span class='fl'>20</span>,
  screening.num <span class='op'>=</span> <span class='cn'>NULL</span>,
  warm.start <span class='op'>=</span> <span class='cn'>TRUE</span>,
  nfolds <span class='op'>=</span> <span class='fl'>5</span>,
  cov.update <span class='op'>=</span> <span class='cn'>TRUE</span>,
  newton <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>"exact"</span>, <span class='st'>"approx"</span><span class='op'>)</span>,
  newton.thresh <span class='op'>=</span> <span class='fl'>1e-06</span>,
  max.newton.iter <span class='op'>=</span> <span class='cn'>NULL</span>,
  early.stop <span class='op'>=</span> <span class='cn'>FALSE</span>,
  num.threads <span class='op'>=</span> <span class='fl'>0</span>,
  seed <span class='op'>=</span> <span class='fl'>1</span>,
  <span class='va'>...</span>
<span class='op'>)</span>

<span class='co'># S3 method for formula</span>
<span class='fu'>abess</span><span class='op'>(</span><span class='va'>formula</span>, <span class='va'>data</span>, <span class='va'>subset</span>, <span class='va'>na.action</span>, <span class='va'>...</span><span class='op'>)</span></pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>Input matrix, of dimension \(n \times p\); each row is an observation
vector and each column is a predictor/feature/variable. 
Can be in sparse matrix format (inherit from class <code>"dgCMatrix"</code> in package <code>Matrix</code>).</p></td>
    </tr>
    <tr>
      <th>y</th>
      <td><p>The response variable, of <code>n</code> observations. 
For <code>family = "binomial"</code> should have two levels. 
For <code>family="poisson"</code>, <code>y</code> should be a vector with positive integer. 
For <code>family = "cox"</code>, <code>y</code> should be a <code>Surv</code> object returned 
by the <code>survival</code> package (recommended) or 
a two-column matrix with columns named <code>"time"</code> and <code>"status"</code>.
For <code>family = "mgaussian"</code>, <code>y</code> should be a matrix of quantitative responses.
For <code>family = "multinomial"</code>, <code>y</code> should be a factor of at least three levels.
Note that, for either <code>"binomial"</code> or <code>"multinomial"</code>, 
if y is presented as a numerical vector, it will be coerced into a factor.</p></td>
    </tr>
    <tr>
      <th>family</th>
      <td><p>One of the following models: 
<code>"gaussian"</code> (continuous response), 
<code>"binomial"</code> (binary response), 
<code>"poisson"</code> (non-negative count), 
<code>"cox"</code> (left-censored response), 
<code>"mgaussian"</code> (multivariate continuous response).
Depending on the response. Any unambiguous substring can be given.</p></td>
    </tr>
    <tr>
      <th>tune.path</th>
      <td><p>The method to be used to select the optimal support size. For
<code>tune.path = "sequence"</code>, we solve the best subset selection problem for each size in <code>support.size</code>.
For <code>tune.path = "gsection"</code>, we solve the best subset selection problem with support size ranged in <code>gs.range</code>,
where the specific support size to be considered is determined by golden section.</p></td>
    </tr>
    <tr>
      <th>tune.type</th>
      <td><p>The type of criterion for choosing the support size. 
Available options are <code>"gic"</code>, <code>"ebic"</code>, <code>"bic"</code>, <code>"aic"</code> and <code>"cv"</code>.
Default is <code>"gic"</code>.</p></td>
    </tr>
    <tr>
      <th>weight</th>
      <td><p>Observation weights. When <code>weight = NULL</code>, 
we set <code>weight = 1</code> for each observation as default.</p></td>
    </tr>
    <tr>
      <th>normalize</th>
      <td><p>Options for normalization. <code>normalize = 0</code> for no normalization. 
<code>normalize = 1</code> for subtracting the mean of columns of <code>x</code>.
<code>normalize = 2</code> for scaling the columns of <code>x</code> to have \(\sqrt n\) norm.
<code>normalize = 3</code> for subtracting the means of the columns of <code>x</code> and <code>y</code>, and also
normalizing the columns of <code>x</code> to have \(\sqrt n\) norm.
If <code>normalize = NULL</code>, <code>normalize</code> will be set <code>1</code> for <code>"gaussian"</code>,
<code>2</code> for <code>"binomial"</code>. Default is <code>normalize = NULL</code>.</p></td>
    </tr>
    <tr>
      <th>c.max</th>
      <td><p>an integer splicing size. Default is: <code>c.max = 2</code>.</p></td>
    </tr>
    <tr>
      <th>support.size</th>
      <td><p>An integer vector representing the alternative support sizes. 
Only used for <code>tune.path = "sequence"</code>. Default is <code>0:min(n, round(n/(log(log(n))log(p))))</code>.</p></td>
    </tr>
    <tr>
      <th>gs.range</th>
      <td><p>A integer vector with two elements. 
The first element is the minimum model size considered by golden-section, 
the later one is the maximum one. Default is <code>gs.range = c(1, min(n, round(n/(log(log(n))log(p)))))</code>.
Not available now.</p></td>
    </tr>
    <tr>
      <th>lambda</th>
      <td><p>A single lambda value for regularized best subset selection. Default is 0.</p></td>
    </tr>
    <tr>
      <th>always.include</th>
      <td><p>An integer vector containing the indexes of variables that should always be included in the model.</p></td>
    </tr>
    <tr>
      <th>group.index</th>
      <td><p>A vector of integers indicating the which group each variable is in.
For variables in the same group, they should be located in adjacent columns of <code>x</code>
and their corresponding index in <code>group.index</code> should be the same.
Denote the first group as <code>1</code>, the second <code>2</code>, etc.
If you do not fit a model with a group structure,
please set <code>group.index = NULL</code> (the default).</p></td>
    </tr>
    <tr>
      <th>splicing.type</th>
      <td><p>Optional type for splicing. 
If <code>splicing.type = 1</code>, the number of variables to be spliced is 
<code>c.max</code>, ..., <code>1</code>; if <code>splicing.type = 2</code>, 
the number of variables to be spliced is <code>c.max</code>, <code>c.max/2</code>, ..., <code>1</code>.
(Default: <code>splicing.type = 2</code>.)</p></td>
    </tr>
    <tr>
      <th>max.splicing.iter</th>
      <td><p>The maximum number of performing splicing algorithm. 
In most of the case, only a few times of splicing iteration can guarantee the convergence. 
Default is <code>max.splicing.iter = 20</code>.</p></td>
    </tr>
    <tr>
      <th>screening.num</th>
      <td><p>An integer number. Preserve <code>screening.num</code> number of predictors with the largest 
marginal maximum likelihood estimator before running algorithm.</p></td>
    </tr>
    <tr>
      <th>warm.start</th>
      <td><p>Whether to use the last solution as a warm start. Default is <code>warm.start = TRUE</code>.</p></td>
    </tr>
    <tr>
      <th>nfolds</th>
      <td><p>The number of folds in cross-validation. Default is <code>nfolds = 5</code>.</p></td>
    </tr>
    <tr>
      <th>cov.update</th>
      <td><p>A logical value only used for <code>family = "gaussian"</code>. If <code>cov.update = TRUE</code>, 
use a covariance-based implementation; otherwise, a naive implementation. 
The naive method is more efficient than covariance-based method only when \(p &gt;&gt; n\). 
Default: <code>cov.update = TRUE</code>.</p></td>
    </tr>
    <tr>
      <th>newton</th>
      <td><p>A character specify the Newton's method for fitting generalized linear models, 
it should be either <code>newton = "exact"</code> or <code>newton = "approx"</code>.
If <code>newton = "exact"</code>, then the exact hessian is used, 
while <code>newton = "approx"</code> uses diagonal entry of the hessian, 
and can be faster (especially when <code>family = "cox"</code>).</p></td>
    </tr>
    <tr>
      <th>newton.thresh</th>
      <td><p>a numeric value for controlling positive convergence tolerance. 
The Newton's iterations converge when \(|dev - dev_{old}|/(|dev| + 0.1)&lt;\) <code>newton.thresh</code>.</p></td>
    </tr>
    <tr>
      <th>max.newton.iter</th>
      <td><p>a integer giving the maximal number of Newton's iteration iterations.
Default is <code>max.newton.iter = 10</code> if <code>newton = "exact"</code>, and <code>max.newton.iter = 60</code> if <code>newton = "approx"</code>.</p></td>
    </tr>
    <tr>
      <th>early.stop</th>
      <td><p>A boolean value decide whether early stopping. 
If <code>early.stop = TRUE</code>, algorithm will stop if the last tuning value less than the existing one. 
Default: <code>early.stop = FALSE</code>.</p></td>
    </tr>
    <tr>
      <th>num.threads</th>
      <td><p>An integer decide the number of threads to be 
concurrently used for cross-validation (i.e., <code>tune.type = "cv"</code>). 
If <code>num.threads = 0</code>, then all of available cores will be used. 
Default: <code>num.threads = 0</code>.</p></td>
    </tr>
    <tr>
      <th>seed</th>
      <td><p>Seed to be used to divide the sample into cross-validation folds. 
Default is <code>seed = 1</code>.</p></td>
    </tr>
    <tr>
      <th>...</th>
      <td><p>further arguments to be passed to or from methods.</p></td>
    </tr>
    <tr>
      <th>formula</th>
      <td><p>an object of class "<code>formula</code>": 
a symbolic description of the model to be fitted. 
The details of model specification are given in the "Details" section of "<code><a href='https://rdrr.io/r/stats/formula.html'>formula</a></code>".</p></td>
    </tr>
    <tr>
      <th>data</th>
      <td><p>a data frame containing the variables in the <code>formula</code>.</p></td>
    </tr>
    <tr>
      <th>subset</th>
      <td><p>an optional vector specifying a subset of observations to be used.</p></td>
    </tr>
    <tr>
      <th>na.action</th>
      <td><p>a function which indicates 
what should happen when the data contain <code>NA</code>s. 
Defaults to <code><a href='https://rdrr.io/r/base/options.html'>getOption("na.action")</a></code>.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A S3 <code>abess</code> class object, which is a <code>list</code> with the following components:</p>
<dt>beta</dt><dd><p>A \(p\)-by-<code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code> matrix of coefficients for univariate family, stored in column format;
while a list of <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code> coefficients matrix (with size \(p\)-by-<code><a href='https://rdrr.io/r/base/nrow.html'>ncol(y)</a></code>) for multivariate family.</p></dd>
<dt>intercept</dt><dd><p>An intercept vector of length <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code> for univariate family; 
while a list of <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code> intercept vector (with size <code><a href='https://rdrr.io/r/base/nrow.html'>ncol(y)</a></code>) for multivariate family.</p></dd>
<dt>dev</dt><dd><p>the deviance of length <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code>.</p></dd>
<dt>tune.value</dt><dd><p>A value of tuning criterion of length <code><a href='https://rdrr.io/r/base/length.html'>length(support.size)</a></code>.</p></dd>
<dt>nobs</dt><dd><p>The number of sample used for training.</p></dd>
<dt>nvars</dt><dd><p>The number of variables used for training.</p></dd>
<dt>family</dt><dd><p>Type of the model.</p></dd>
<dt>tune.path</dt><dd><p>The path type for tuning parameters.</p></dd>
<dt>support.size</dt><dd><p>The actual <code>support.size</code> values used. 
Note that it is not necessary the same as the input  
if the later have non-integer values or duplicated values.</p></dd>
<dt>best.size</dt><dd><p>The best support size selected by the tuning value.</p></dd> 
<dt>tune.type</dt><dd><p>The criterion type for tuning parameters.</p></dd>
<dt>tune.path</dt><dd><p>The strategy for tuning parameters.</p></dd>
<dt>screening.vars</dt><dd><p>The character vector specify the feature 
selected by feature screening. 
It would be an empty character vector if <code>screening.num = 0</code>.</p></dd>
<dt>call</dt><dd><p>The original call to <code>abess</code>.</p></dd>

    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>Best-subset selection aims to find a small subset of predictors, 
so that the resulting model is expected to have the most desirable prediction accuracy. 
Best-subset selection problem under the support size \(s\) is
$$\min_\beta -2 \log L(\beta) \;\;{\rm s.t.}\;\; \|\beta\|_0 \leq s,$$
where \(L(\beta)\) is arbitrary convex functions. In
the GLM case, \(\log L(\beta)\) is the log-likelihood function; in the Cox
model, \(\log L(\beta)\) is the log partial-likelihood function.</p>
<p>The best subset selection problem is solved by the "abess" algorithm in this package, see Zhu (2020) for details. 
Under mild conditions, the algorithm exactly solve this problem in polynomial time. 
This algorithm exploits the idea of sequencing and splicing to reach a stable solution in finite steps
when \(s\) is fixed. 
To find the optimal support size \(s\), 
we provide various criterion like GIC, AIC, BIC and cross-validation error to determine it.</p>
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>A polynomial algorithm for best-subset selection problem. Junxian Zhu, Canhong Wen, Jin Zhu, Heping Zhang, Xueqin Wang. Proceedings of the National Academy of Sciences Dec 2020, 117 (52) 33117-33123; DOI: 10.1073/pnas.2014241117</p>
<p>Sure independence screening for ultrahigh dimensional feature space. Fan, J. and Lv, J. (2008), Journal of the Royal Statistical Society: Series B (Statistical Methodology), 70: 849-911. https://doi.org/10.1111/j.1467-9868.2008.00674.x</p>
<p>Targeted Inference Involving High-Dimensional Data Using Nuisance Penalized Regression. Qiang Sun &amp; Heping Zhang (2020). Journal of the American Statistical Association, DOI: 10.1080/01621459.2020.1737079</p>
<p>Certifiably Polynomial Algorithm for Best Group Subset Selection. Zhang, Yanhang, Junxian Zhu, Jin Zhu, and Xueqin Wang (2021). arXiv preprint arXiv:2104.12576.</p>
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p><code><a href='print.abess.html'>print.abess</a></code>, 
<code><a href='predict.abess.html'>predict.abess</a></code>, 
<code><a href='coef.abess.html'>coef.abess</a></code>, 
<code><a href='extract.html'>extract.abess</a></code>,
<code><a href='plot.abess.html'>plot.abess</a></code>,
<code><a href='deviance.abess.html'>deviance.abess</a></code>.</p></div>
    <h2 class="hasAnchor" id="author"><a class="anchor" href="#author"></a>Author</h2>

    <p>Jin Zhu, Junxian Zhu, Canhong Wen, Heping Zhang, Xueqin Wang</p>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># \donttest{</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/abess-team/abess'>abess</a></span><span class='op'>)</span>
<span class='va'>n</span> <span class='op'>&lt;-</span> <span class='fl'>100</span>
<span class='va'>p</span> <span class='op'>&lt;-</span> <span class='fl'>20</span>
<span class='va'>support.size</span> <span class='op'>&lt;-</span> <span class='fl'>3</span>

<span class='co'>################ linear model ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span>
<span class='co'>## helpful generic functions:</span>
<span class='fu'><a href='https://rdrr.io/r/base/print.html'>print</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span>
</div><div class='output co'>#&gt; Call:
#&gt; abess.default(x = dataset[["x"]], y = dataset[["y"]])
#&gt; 
#&gt;    support.size       dev      GIC
#&gt; 1             0 17805.684 978.7273
#&gt; 2             1 10163.270 927.2286
#&gt; 3             2  4407.395 848.2540
#&gt; 4             3  1842.745 765.6262
#&gt; 5             4  1667.015 760.1791
#&gt; 6             5  1594.016 760.2763
#&gt; 7             6  1543.874 761.6551
#&gt; 8             7  1518.615 764.5805
#&gt; 9             8  1500.112 767.9297
#&gt; 10            9  1486.034 771.5618
#&gt; 11           10  1473.749 775.3067
#&gt; 12           11  1460.411 778.9725
#&gt; 13           12  1452.290 782.9899
#&gt; 14           13  1444.224 787.0080
#&gt; 15           14  1439.776 791.2745
#&gt; 16           15  1437.522 795.6929
#&gt; 17           16  1435.833 800.1504
#&gt; 18           17  1434.539 804.6352
#&gt; 19           18  1433.386 809.1298
#&gt; 20           19  1432.351 813.6327
#&gt; 21           20  1432.225 813.6239</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/stats/coef.html'>coef</a></span><span class='op'>(</span><span class='va'>abess_fit</span>, support.size <span class='op'>=</span> <span class='fl'>3</span><span class='op'>)</span>
</div><div class='output co'>#&gt; 21 x 1 sparse Matrix of class "dgCMatrix"
#&gt;                     3
#&gt; (intercept) -4.369861
#&gt; x1           .       
#&gt; x2           .       
#&gt; x3           .       
#&gt; x4           .       
#&gt; x5           .       
#&gt; x6          83.270800
#&gt; x7           .       
#&gt; x8           .       
#&gt; x9           .       
#&gt; x10          .       
#&gt; x11          .       
#&gt; x12          .       
#&gt; x13          .       
#&gt; x14         89.689944
#&gt; x15          .       
#&gt; x16          .       
#&gt; x17          .       
#&gt; x18         43.410846
#&gt; x19          .       
#&gt; x20          .       </div><div class='input'><span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>abess_fit</span>, newx <span class='op'>=</span> <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>10</span>, <span class='op'>]</span>, 
        support.size <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>3</span>, <span class='fl'>4</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt;                3           4
#&gt;  [1,]  103.05157   91.524774
#&gt;  [2,]   74.66998   85.359664
#&gt;  [3,] -289.97309 -299.858907
#&gt;  [4,]  -16.35758   -4.241221
#&gt;  [5,]  171.80572  162.807112
#&gt;  [6,]  126.58540  127.021354
#&gt;  [7,] -197.24366 -207.134508
#&gt;  [8,] -126.67823 -142.927367
#&gt;  [9,]  -23.29128  -22.898065
#&gt; [10,] -109.76937 -117.273626</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/utils/str.html'>str</a></span><span class='op'>(</span><span class='fu'><a href='extract.html'>extract</a></span><span class='op'>(</span><span class='va'>abess_fit</span>, <span class='fl'>3</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; List of 7
#&gt;  $ beta        :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
#&gt;   .. ..@ i       : int [1:3] 5 13 17
#&gt;   .. ..@ p       : int [1:2] 0 3
#&gt;   .. ..@ Dim     : int [1:2] 20 1
#&gt;   .. ..@ Dimnames:List of 2
#&gt;   .. .. ..$ : chr [1:20] "x1" "x2" "x3" "x4" ...
#&gt;   .. .. ..$ : chr "3"
#&gt;   .. ..@ x       : num [1:3] 83.3 89.7 43.4
#&gt;   .. ..@ factors : list()
#&gt;  $ intercept   : num -4.37
#&gt;  $ support.size: num 3
#&gt;  $ support.vars: chr [1:3] "x6" "x14" "x18"
#&gt;  $ support.beta: num [1:3] 83.3 89.7 43.4
#&gt;  $ dev         : num 1843
#&gt;  $ tune.value  : num 766</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/stats/deviance.html'>deviance</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span>
</div><div class='output co'>#&gt;  [1] 17805.684 10163.270  4407.395  1842.745  1667.015  1594.016  1543.874
#&gt;  [8]  1518.615  1500.112  1486.034  1473.749  1460.411  1452.290  1444.224
#&gt; [15]  1439.776  1437.522  1435.833  1434.539  1433.386  1432.351  1432.225</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span>
</div><div class='img'><img src='abess-1.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='co'>################ logistic model ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span>, family <span class='op'>=</span> <span class='st'>"binomial"</span><span class='op'>)</span>
<span class='co'>## allow cross-validation to tuning</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, 
                   family <span class='op'>=</span> <span class='st'>"binomial"</span>, tune.type <span class='op'>=</span> <span class='st'>"cv"</span><span class='op'>)</span>
<span class='va'>abess_fit</span>
</div><div class='output co'>#&gt; Call:
#&gt; abess.default(x = dataset[["x"]], y = dataset[["y"]], family = "binomial", 
#&gt;     tune.type = "cv")
#&gt; 
#&gt;    support.size       dev        cv
#&gt; 1             0  68.59298 13.888785
#&gt; 2             1  46.69364  9.467560
#&gt; 3             2  22.31417  4.795569
#&gt; 4             3  17.60334  5.453128
#&gt; 5             4  16.86618  9.348024
#&gt; 6             5  16.15675 14.748842
#&gt; 7             6 233.15206 40.167095
#&gt; 8             7 207.31665 45.498779
#&gt; 9             8 195.19859 55.460595
#&gt; 10            9 254.11086 71.431879
#&gt; 11           10 185.26512 73.733246
#&gt; 12           11 113.86185 80.906253
#&gt; 13           12 102.55145 81.789855
#&gt; 14           13 161.15186 84.576775
#&gt; 15           14 154.05620 84.303964
#&gt; 16           15  90.60221 85.743672
#&gt; 17           16 171.54659 87.080871
#&gt; 18           17 155.09793 87.686199
#&gt; 19           18  91.13829 88.334593
#&gt; 20           19  95.02055 88.585575
#&gt; 21           20 176.73201 88.764208</div><div class='input'>
<span class='co'>################ poisson model ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span>, family <span class='op'>=</span> <span class='st'>"poisson"</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, 
                   family <span class='op'>=</span> <span class='st'>"poisson"</span>, tune.type <span class='op'>=</span> <span class='st'>"cv"</span><span class='op'>)</span>
<span class='va'>abess_fit</span>
</div><div class='output co'>#&gt; Call:
#&gt; abess.default(x = dataset[["x"]], y = dataset[["y"]], family = "poisson", 
#&gt;     tune.type = "cv")
#&gt; 
#&gt;    support.size        dev        cv
#&gt; 1             0   44.95340  10.19365
#&gt; 2             1  -31.62397   3.28437
#&gt; 3             2 -100.57515 -10.57295
#&gt; 4             3 -157.18472 -30.45472
#&gt; 5             4 -160.75596 -31.01768
#&gt; 6             5 -163.01916 -30.63952
#&gt; 7             6 -164.82977 -30.13028
#&gt; 8             7 -166.39686 -26.74170
#&gt; 9             8 -167.33059 -27.33824
#&gt; 10            9 -168.30048 -27.42207
#&gt; 11           10 -168.98526 -27.25688
#&gt; 12           11 -169.76250 -26.64811
#&gt; 13           12 -170.25995 -27.38531
#&gt; 14           13 -171.31745 -28.11082
#&gt; 15           14 -171.54370 -28.38129
#&gt; 16           15 -171.74975 -28.63368
#&gt; 17           16 -171.85325 -28.08725
#&gt; 18           17 -171.91807 -27.93866
#&gt; 19           18 -171.94049 -28.14687
#&gt; 20           19 -171.94879 -27.96197
#&gt; 21           20 -171.95969 -27.89558</div><div class='input'>
<span class='co'>################ Cox model ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span>, family <span class='op'>=</span> <span class='st'>"cox"</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, 
                   family <span class='op'>=</span> <span class='st'>"cox"</span>, tune.type <span class='op'>=</span> <span class='st'>"cv"</span><span class='op'>)</span>

<span class='co'>################ Multivariate gaussian model ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span>, family <span class='op'>=</span> <span class='st'>"mgaussian"</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, 
                   family <span class='op'>=</span> <span class='st'>"mgaussian"</span>, tune.type <span class='op'>=</span> <span class='st'>"cv"</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span><span class='op'>(</span><span class='va'>abess_fit</span>, type <span class='op'>=</span> <span class='st'>"l2norm"</span><span class='op'>)</span>
</div><div class='img'><img src='abess-2.png' alt='' width='700' height='433' /></div><div class='input'>
<span class='co'>################ Multinomial model (multi-classification) ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span>, family <span class='op'>=</span> <span class='st'>"multinomial"</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, 
                   family <span class='op'>=</span> <span class='st'>"multinomial"</span>, tune.type <span class='op'>=</span> <span class='st'>"cv"</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span><span class='op'>(</span><span class='va'>abess_fit</span>, newx <span class='op'>=</span> <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>10</span>, <span class='op'>]</span>, 
        support.size <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='fl'>3</span>, <span class='fl'>4</span><span class='op'>)</span>, type <span class='op'>=</span> <span class='st'>"response"</span><span class='op'>)</span>
</div><div class='output co'>#&gt; $`3`
#&gt;                  1            2             
#&gt;  [1,] 1.671671e-01 8.328200e-01 1.287189e-05
#&gt;  [2,] 9.911159e-01 7.642165e-07 8.883312e-03
#&gt;  [3,] 1.872056e-08 3.729703e-07 9.999996e-01
#&gt;  [4,] 5.729829e-09 1.000000e+00 9.354748e-11
#&gt;  [5,] 9.958075e-01 2.464085e-08 4.192443e-03
#&gt;  [6,] 7.875359e-01 1.578117e-01 5.465246e-02
#&gt;  [7,] 1.029619e-04 8.793505e-01 1.205466e-01
#&gt;  [8,] 1.559240e-05 9.916642e-01 8.320255e-03
#&gt;  [9,] 1.070042e-03 2.624924e-02 9.726807e-01
#&gt; [10,] 2.169661e-03 5.300874e-08 9.978303e-01
#&gt; 
#&gt; $`4`
#&gt;                  1            2             
#&gt;  [1,] 1.519011e-01 8.480973e-01 1.651999e-06
#&gt;  [2,] 9.995554e-01 2.537617e-08 4.446060e-04
#&gt;  [3,] 6.512419e-09 7.648814e-08 9.999999e-01
#&gt;  [4,] 1.560530e-10 1.000000e+00 2.877017e-12
#&gt;  [5,] 9.776994e-01 2.401934e-09 2.230056e-02
#&gt;  [6,] 8.981233e-01 9.788248e-02 3.994230e-03
#&gt;  [7,] 4.574281e-05 9.272144e-01 7.273983e-02
#&gt;  [8,] 2.845467e-06 9.969577e-01 3.039405e-03
#&gt;  [9,] 2.003835e-04 1.235827e-02 9.874413e-01
#&gt; [10,] 2.127882e-03 3.456984e-09 9.978721e-01
#&gt; </div><div class='input'>
<span class='co'>########## Best group subset selection #############</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span><span class='op'>)</span>
<span class='va'>group_index</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/rep.html'>rep</a></span><span class='op'>(</span><span class='fl'>1</span><span class='op'>:</span><span class='fl'>10</span>, each <span class='op'>=</span> <span class='fl'>2</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, group.index <span class='op'>=</span> <span class='va'>group_index</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/str.html'>str</a></span><span class='op'>(</span><span class='fu'><a href='extract.html'>extract</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; List of 7
#&gt;  $ beta        :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
#&gt;   .. ..@ i       : int [1:8] 4 5 12 13 14 15 16 17
#&gt;   .. ..@ p       : int [1:2] 0 8
#&gt;   .. ..@ Dim     : int [1:2] 20 1
#&gt;   .. ..@ Dimnames:List of 2
#&gt;   .. .. ..$ : chr [1:20] "x1" "x2" "x3" "x4" ...
#&gt;   .. .. ..$ : chr "4"
#&gt;   .. ..@ x       : num [1:8] 1.992 82.397 -0.735 88.545 -4.368 ...
#&gt;   .. ..@ factors : list()
#&gt;  $ intercept   : num -4.07
#&gt;  $ support.size: int 4
#&gt;  $ support.vars: chr [1:8] "x5" "x6" "x13" "x14" ...
#&gt;  $ support.beta: num [1:8] 1.992 82.397 -0.735 88.545 -4.368 ...
#&gt;  $ dev         : num 1639
#&gt;  $ tune.value  : num 768</div><div class='input'>
<span class='co'>################ Golden section searching ################</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, tune.path <span class='op'>=</span> <span class='st'>"gsection"</span><span class='op'>)</span>
<span class='va'>abess_fit</span>
</div><div class='output co'>#&gt; Call:
#&gt; abess.default(x = dataset[["x"]], y = dataset[["y"]], tune.path = "gsection")
#&gt; 
#&gt;   support.size      dev      GIC
#&gt; 1            3 1842.745 765.6262
#&gt; 2            4 1667.015 760.1791
#&gt; 3            5 1594.016 760.2763
#&gt; 4            6 1543.874 761.6551
#&gt; 5            8 1500.112 767.9297
#&gt; 6           13 1444.224 787.0080</div><div class='input'>
<span class='co'>################ Feature screening ################</span>
<span class='va'>p</span> <span class='op'>&lt;-</span> <span class='fl'>1000</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span>, 
                   screening.num <span class='op'>=</span> <span class='fl'>100</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/str.html'>str</a></span><span class='op'>(</span><span class='fu'><a href='extract.html'>extract</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; List of 7
#&gt;  $ beta        :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
#&gt;   .. ..@ i       : int [1:3] 288 642 780
#&gt;   .. ..@ p       : int [1:2] 0 3
#&gt;   .. ..@ Dim     : int [1:2] 1000 1
#&gt;   .. ..@ Dimnames:List of 2
#&gt;   .. .. ..$ : chr [1:1000] "x1" "x2" "x3" "x4" ...
#&gt;   .. .. ..$ : chr "3"
#&gt;   .. ..@ x       : num [1:3] 145.3 51.9 160.1
#&gt;   .. ..@ factors : list()
#&gt;  $ intercept   : num 5.53
#&gt;  $ support.size: int 3
#&gt;  $ support.vars: chr [1:3] "x289" "x643" "x781"
#&gt;  $ support.beta: num [1:3] 145.3 51.9 160.1
#&gt;  $ dev         : num 3643
#&gt;  $ tune.value  : num 841</div><div class='input'>
<span class='co'>################ Sparse predictor ################</span>
<span class='kw'><a href='https://rdrr.io/r/base/library.html'>require</a></span><span class='op'>(</span><span class='va'><a href='http://Matrix.R-forge.R-project.org/'>Matrix</a></span><span class='op'>)</span>
</div><div class='output co'>#&gt; <span class='message'>Loading required package: Matrix</span></div><div class='input'><span class='va'>p</span> <span class='op'>&lt;-</span> <span class='fl'>1000</span>
<span class='va'>dataset</span> <span class='op'>&lt;-</span> <span class='fu'><a href='generate.data.html'>generate.data</a></span><span class='op'>(</span><span class='va'>n</span>, <span class='va'>p</span>, <span class='va'>support.size</span><span class='op'>)</span>
<span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>[</span><span class='fu'><a href='https://rdrr.io/r/base/MathFun.html'>abs</a></span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span> <span class='op'>&lt;</span> <span class='fl'>1</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='fl'>0</span>
<span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/Matrix/man/Matrix.html'>Matrix</a></span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"x"</span><span class='op'>]</span><span class='op'>]</span>, <span class='va'>dataset</span><span class='op'>[[</span><span class='st'>"y"</span><span class='op'>]</span><span class='op'>]</span><span class='op'>)</span>
<span class='fu'><a href='https://rdrr.io/r/utils/str.html'>str</a></span><span class='op'>(</span><span class='fu'><a href='extract.html'>extract</a></span><span class='op'>(</span><span class='va'>abess_fit</span><span class='op'>)</span><span class='op'>)</span>
</div><div class='output co'>#&gt; List of 7
#&gt;  $ beta        :Formal class 'dgCMatrix' [package "Matrix"] with 6 slots
#&gt;   .. ..@ i       : int [1:2] 288 780
#&gt;   .. ..@ p       : int [1:2] 0 2
#&gt;   .. ..@ Dim     : int [1:2] 1000 1
#&gt;   .. ..@ Dimnames:List of 2
#&gt;   .. .. ..$ : chr [1:1000] "x1" "x2" "x3" "x4" ...
#&gt;   .. .. ..$ : chr "2"
#&gt;   .. ..@ x       : num [1:2] 147 171
#&gt;   .. ..@ factors : list()
#&gt;  $ intercept   : num -10.4
#&gt;  $ support.size: int 2
#&gt;  $ support.vars: chr [1:2] "x289" "x781"
#&gt;  $ support.beta: num [1:2] 147 171
#&gt;  $ dev         : num 14531
#&gt;  $ tune.value  : num 980</div><div class='input'><span class='co'># }</span>
<span class='co'># \donttest{</span>
<span class='co'>################  Formula interface  ################</span>
<span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='st'>"trim32"</span><span class='op'>)</span>
<span class='va'>abess_fit</span> <span class='op'>&lt;-</span> <span class='fu'>abess</span><span class='op'>(</span><span class='va'>y</span> <span class='op'>~</span> <span class='va'>.</span>, data <span class='op'>=</span> <span class='va'>trim32</span><span class='op'>)</span>
<span class='va'>abess_fit</span>
</div><div class='output co'>#&gt; Call:
#&gt; abess.formula(formula = y ~ ., data = trim32)
#&gt; 
#&gt;    support.size         dev       GIC
#&gt; 1             0 0.020738622 -465.0909
#&gt; 2             1 0.008176953 -567.0402
#&gt; 3             2 0.006186442 -590.7832
#&gt; 4             3 0.004791180 -611.7211
#&gt; 5             4 0.004418203 -611.7142
#&gt; 6             5 0.003928650 -616.0745
#&gt; 7             6 0.003616324 -616.2830
#&gt; 8             7 0.003363741 -615.2394
#&gt; 9             8 0.003169559 -612.6426
#&gt; 10            9 0.002856742 -615.3798
#&gt; 11           10 0.002594231 -617.2147
#&gt; 12           11 0.002375152 -618.0700
#&gt; 13           12 0.002274280 -613.5456</div><div class='input'><span class='co'># }</span>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Jin Zhu, Kangkang Jiang, Yanhang Zhang, Liyuan Hu, Junhao Huang, Junxian Zhu, Canhong Wen, Heping Zhang, Xueqin Wang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


